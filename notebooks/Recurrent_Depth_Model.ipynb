{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b974fc3cc5849ae844682ae72179f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f450fd1c377842eeb2f91c098bcbe621",
              "IPY_MODEL_fc6d8c71d0ab4d5bbb283c70e4484502",
              "IPY_MODEL_aad8f375c6b2453380b055c046a6ef49"
            ],
            "layout": "IPY_MODEL_9b59df6523bb412680e926826af09929"
          }
        },
        "f450fd1c377842eeb2f91c098bcbe621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d684e8f285f947e6ad7d2ec247806361",
            "placeholder": "​",
            "style": "IPY_MODEL_91e95c614a0349b38f0ab20acb7e361a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fc6d8c71d0ab4d5bbb283c70e4484502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_605cced7fbe243e4b139b5d6c2aa6df4",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f67625befc4241bebd17244fcd4a7975",
            "value": 4
          }
        },
        "aad8f375c6b2453380b055c046a6ef49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e287a0fe3b134af38a164ae9c29a5567",
            "placeholder": "​",
            "style": "IPY_MODEL_082148c31e2c47e8aaeebd3d3960b202",
            "value": " 4/4 [00:01&lt;00:00,  3.34it/s]"
          }
        },
        "9b59df6523bb412680e926826af09929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d684e8f285f947e6ad7d2ec247806361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e95c614a0349b38f0ab20acb7e361a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "605cced7fbe243e4b139b5d6c2aa6df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67625befc4241bebd17244fcd4a7975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e287a0fe3b134af38a164ae9c29a5567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082148c31e2c47e8aaeebd3d3960b202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Based on the paper [Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach](https://arxiv.org/pdf/2502.05171), the Huginn-0125 model takes advantage of inference time recurrent layers.\n",
        "\n",
        "Let's look at exactly what this means:\n",
        "\n",
        "![image](https://i.imgur.com/pTSofbN.png)\n",
        "\n",
        "So when we do inference, we have the ability to select how many green boxes we are using."
      ],
      "metadata": {
        "id": "majs0XEfUNzn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "5b974fc3cc5849ae844682ae72179f05",
            "f450fd1c377842eeb2f91c098bcbe621",
            "fc6d8c71d0ab4d5bbb283c70e4484502",
            "aad8f375c6b2453380b055c046a6ef49",
            "9b59df6523bb412680e926826af09929",
            "d684e8f285f947e6ad7d2ec247806361",
            "91e95c614a0349b38f0ab20acb7e361a",
            "605cced7fbe243e4b139b5d6c2aa6df4",
            "f67625befc4241bebd17244fcd4a7975",
            "e287a0fe3b134af38a164ae9c29a5567",
            "082148c31e2c47e8aaeebd3d3960b202"
          ]
        },
        "id": "fLHJYCN_AB_z",
        "outputId": "47c0ceca-c8d6-4013-d966-73de2982384b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b974fc3cc5849ae844682ae72179f05"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"tomg-group-umd/huginn-0125\", torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"tomg-group-umd/huginn-0125\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "VZoM_YWmCPqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "config = GenerationConfig(max_length=256, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"],\n",
        "                          use_cache=True,\n",
        "                          do_sample=False, temperature=None, top_k=None, top_p=None, min_p=None,\n",
        "                          return_dict_in_generate=True,\n",
        "                          eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBC8vS59AsSR",
        "outputId": "3437b9d7-5f03-4602-eca6-5f3fb13a6ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RavenForCausalLM(\n",
              "  (transformer): ModuleDict(\n",
              "    (wte): Embedding(65536, 5280)\n",
              "    (prelude): ModuleList(\n",
              "      (0-1): 2 x SandwichBlock(\n",
              "        (norm_1): RMSNorm()\n",
              "        (attn): CausalSelfAttention(\n",
              "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
              "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
              "        )\n",
              "        (norm_2): RMSNorm()\n",
              "        (mlp): GatedMLP(\n",
              "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
              "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
              "          (nonlin): SiLU()\n",
              "        )\n",
              "        (norm_3): RMSNorm()\n",
              "        (norm_4): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (adapter): Linear(in_features=10560, out_features=5280, bias=False)\n",
              "    (core_block): ModuleList(\n",
              "      (0-3): 4 x SandwichBlock(\n",
              "        (norm_1): RMSNorm()\n",
              "        (attn): CausalSelfAttention(\n",
              "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
              "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
              "        )\n",
              "        (norm_2): RMSNorm()\n",
              "        (mlp): GatedMLP(\n",
              "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
              "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
              "          (nonlin): SiLU()\n",
              "        )\n",
              "        (norm_3): RMSNorm()\n",
              "        (norm_4): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (coda): ModuleList(\n",
              "      (0-1): 2 x SandwichBlock(\n",
              "        (norm_1): RMSNorm()\n",
              "        (attn): CausalSelfAttention(\n",
              "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
              "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
              "        )\n",
              "        (norm_2): RMSNorm()\n",
              "        (mlp): GatedMLP(\n",
              "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
              "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
              "          (nonlin): SiLU()\n",
              "        )\n",
              "        (norm_3): RMSNorm()\n",
              "        (norm_4): RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (ln_f): RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=5280, out_features=65536, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clip Example"
      ],
      "metadata": {
        "id": "I4W_VkcMNcKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\" : \"You are a helpful assistant.\"})\n",
        "messages.append({\"role\": \"user\", \"content\" : \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"})\n",
        "chat_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "print(chat_input)\n",
        "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "\n",
        "outputs = model.generate(input_ids, config, num_steps=4, tokenizer=tokenizer)\n",
        "tokenizer.batch_decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aZKpI4uCbsk",
        "outputId": "c2578461-86b6-401c-978d-1476305a1d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_text|><|begin_header|>system<|end_header|>\n",
            "\n",
            "You are a helpful assistant.<|end_turn|><|begin_header|>user<|end_header|>\n",
            "\n",
            "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system\\n\\nYou are a helpful assistant.user\\n\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?Huginn\\n\\nNatalia sold 48 clips in April. In May, she sold half as many clips as she sold in April. In total, Natalia sold 48 + 48 = 96 clips in April and May.']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "\n",
        "outputs = model.generate(input_ids, config, num_steps=8, tokenizer=tokenizer)\n",
        "tokenizer.batch_decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moEelOhzD3pO",
        "outputId": "27dd926a-1a29-43d1-9160-96fc053c468e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system\\n\\nYou are a helpful assistant.user\\n\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?Huginn\\n\\nNatalia sold 48 clips in April.\\nIn May, she sold half as many clips as in April, which is 48 / 2 = 24 clips.\\nTo find the total number of clips sold in April and May, we add the number of clips sold in each month: 48 + 24 = 72 clips.\\nTherefore, Natalia sold 72 clips altogether in April and May.']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "\n",
        "outputs = model.generate(input_ids, config, num_steps=16, tokenizer=tokenizer)\n",
        "tokenizer.batch_decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RZ7E7vRED12",
        "outputId": "1700de19-8334-4c8f-be9a-c29e39019c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system\\n\\nYou are a helpful assistant.user\\n\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?Huginn\\n\\nNatalia sold 48 clips in April. In May, she sold half as many clips as in April, which means she sold 48 / 2 = 24 clips in May. To find the total number of clips she sold in April and May, we add the number of clips sold in each month: 48 + 24 = 72 clips. Therefore, Natalia sold 72 clips altogether in April and May.']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weight Example"
      ],
      "metadata": {
        "id": "or-mu4OsNwuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "messages.append({\"role\": \"system\", \"content\" : \"You are a helpful assistant.\"})\n",
        "messages.append({\"role\": \"user\", \"content\" : \"Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?\"})\n",
        "chat_input = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "print(chat_input)\n",
        "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "\n",
        "outputs = model.generate(input_ids, config, num_steps=4, tokenizer=tokenizer)\n",
        "tokenizer.batch_decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVk7YbhUNye_",
        "outputId": "7adaa9d0-9842-48c7-d069-5362232cd6e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_text|><|begin_header|>system<|end_header|>\n",
            "\n",
            "You are a helpful assistant.<|end_turn|><|begin_header|>user<|end_header|>\n",
            "\n",
            "Ken created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system\\n\\nYou are a helpful assistant.user\\n\\nKen created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?Huginn\\n\\nThe final weight of the box of goodies is 10 pounds.\\nThe weight of the box of jelly beans is 2 pounds.\\nThe weight of the box of brownies is 1 pound.\\nThe weight of the box of gummy worms is 2 pounds.\\nThe weight of the box of double the weight of the box of gummy worms is 2 pounds.\\nThe weight of the box of double the weight of the box of gummy worms is 2 pounds.\\nThe weight of the box of double the weight of the box of gummy worms is 2 pounds.\\nThe weight of the box of double the weight of the box of gummy worms']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "\n",
        "outputs = model.generate(input_ids, config, num_steps=8, tokenizer=tokenizer)\n",
        "tokenizer.batch_decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0QaEAyJN3j9",
        "outputId": "cc894e84-27c0-45a4-8bc6-7f2b0c46491e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['system\\n\\nYou are a helpful assistant.user\\n\\nKen created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?Huginn\\n\\nThe final weight of the box of goodies is 12 pounds.']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
        "\n",
        "outputs = model.generate(input_ids, config, num_steps=16, tokenizer=tokenizer)\n",
        "tokenizer.batch_decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VpxvBDrN58A",
        "outputId": "97961bd4-0f62-42de-b9f0-cc65ded4d967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"system\\n\\nYou are a helpful assistant.user\\n\\nKen created a care package to send to his brother, who was away at boarding school. Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds. Then, he added enough brownies to cause the weight to triple. Next, he added another 2 pounds of jelly beans. And finally, he added enough gummy worms to double the weight once again. What was the final weight of the box of goodies, in pounds?Huginn\\n\\nLet's calculate the final weight of Ken's care package step by step:\\n1. The box initially weighed 2 pounds.\\n2. Ken added enough jelly beans to bring the weight to 2 pounds.\\n3. Then, he added enough brownies to cause the weight to triple.\\n4. The weight tripled to 3 x 2 = 6 pounds.\\n5. Next, Ken added another 2 pounds of jelly beans.\\n6. The weight now becomes 6 + 2 = 8 pounds.\\n7. Finally, Ken added enough gummy worms to double the weight once again.\\n8. The weight doubled to 2 x 8 = 16 pounds.\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}