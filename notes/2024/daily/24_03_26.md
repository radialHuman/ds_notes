## [Is RAG Really Dead? Testing Multi Fact Retrieval & Reasoning in GPT4-128k](https://youtu.be/UlmyyYQGhzc)
### Idea
- Since i/p context window size is increasing in llms
- RAG which takes in a lot of doc and helps in Q&A can be obselete
- TO test if these large i/p token LLMs can replace RAG, it needs to be compared
- Performance needs to be evaluated before dismissing RAG

### Details
- Take a piece of info, divide it up and place it acorss the document
    - upload the doc and ask a question which will combine the divided info and consolidate it in the o/p
    - The divide info is a needle, the doc is the haystack
    - Research shows if needle is in the top of the doc it gets less noticed as the context size increases
    - Since there are multiple needles, its multi needle in haystack
- Second experiment was to retrive and reason
    - it too decreases with increase in needles and context size
    

### Resource
- 

### misc
 
---
