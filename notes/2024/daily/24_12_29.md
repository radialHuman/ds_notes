## [Glider - Small Judge Model with Reasoning - Suited for RAG Pipelines](https://youtu.be/xw8grcKhcOU)
Release date :  Dec 29, 2024
### Idea #judge
- LLM as judge for RAG

### Details
- scores and explains in detail for why the score
- comapritively small model
- fine tuned ms phi model
- rubic scale
- other languages too
- 16GB
```prompt
prompt=""" 
 Analyze the following pass criteria carefully and score the text based on the rubric defined below.
To perform this evaluation, you must:
. Understand the text tags, pass criteria and rubric thoroughly.
. Review the finer details of the text and the rubric.
. Compare the tags to be evaluated to the score descriptions in the rubric.
. Pay close attention to small details that might impact the final score and form accurate associations between tags and pass criteria.
. Write a detailed reasoning justifying your evaluation in a bullet point format.
. The reasoning must summarize the overall strengths and weaknesses of the output while quoting exact phrases from the output wherever required.
. Output a list of words or phrases that you believe are the most important in determining the score.
. Assign a final score based on the scoring rubric.

Data to evaluate: <SYSTEM PROMPT>
User is asking for a refund for a delayed flight. </SYSTEM PROMPT>
<USER PROMPT>
Hi, my flight was delayed by 5 hours and I'd like a refund. Can you help me? </USER PROMPT>

<ASSISTANT REPLY>
I apologize for the inconvenience. I'd be happy to assist you with the refund. However, I need to inform you that our refund policy states t </ASSISTANT REPLY>

Pass Criteria:
* The assistant acknowledges the user's concern and apologizes for the inconvenience.
* The assistant clearly explains the refund policy and its implications.
* The assistant offers alternative solutions (voucher or partial refund).

Rubric:
* Score 1-2: The assistant fails to acknowledge the user's concern or provide a clear explanation of the refund policy.
* Score 3-4: The assistant acknowledges the user's concern and provides a clear explanation of the refund policy, but fails to offer alternat 
*Score 5: The assistant acknowledges the user's concern, provides a clear explanation of the refund policy, and offers alternative solutions

Your output must in the following format:
<reasoning>
[Detailed reasoning justifying your evaluation in a bullet point format according to the specifics defined above] </reasoning>

<highlight>
List of words or phrases that you believe are the most important in determining the score]
</highlight>

<score> [The final integer score assigned based on the scoring rubric]
</score> messages = [
{"role": "user", "content": prompt}, ]
result = pipe(messages) print(result[0]['generated text'])
```
### Resource
https://huggingface.co/PatronusAI/glider

### misc
FLow Judge
Meta Rewarding
Compass Judger
---

## [ModernBERT vs BERT](https://youtu.be/VMpyHZ_fWE8)
Release date :  Dec 29, 2024
### Idea #bert
-   Difference between bert and Modern Bert

### Details
- Context length from 512 to 8k
    - to udnerstand the input better, longer range dependncy
- Has RoPE for positonal embedding
- GeGLU actional function in layers
- Flash Attention2 which switches between local (128 token sliding window) and global (every 3rd layer) attention better
- Done with padding tokens and made packing seq more efficient, saving computational expense
- not only wiki data but also a lot of code
- SOTA in Dec 2024
- 4x faster than BERT for inferencing
- 1/5th memory usage of DebertaV3
- base (149M) and large (394M) variants
- Can be used on comsumer GPU
- backward compatible in code

### Resource


### misc

---

## [Choosing the Best LLM: Tools, Metrics, and Benchmarks Explained](https://youtu.be/TljgQ2ZRT1U)
Release date :  Dec 28, 2024
### Idea #llm
- right open source model for the task
- hf open llm leaderboard

### Details
- \# of parameter to filter
- benchmarks : Google proof QnA, very high bar 448 difficult question phd level
- 

### Resource


### misc

---

## [Optimize Your AI - Quantization Explained](https://youtu.be/K75j8MkwgJ0)
Release date : Dec 28, 2024
### Idea #python
- massive llm models on laptop using quanitzation

### Details
- q4 q8 q2
- llms models are just a colleciton of large volume fo numebrs to be stored with precision
- usually 32 bit
- this takes a lot of ram
- k quants : small numebrs and big numbers take different locations 
- k_s k_m k_l : small large medium
- more speed, less space when quantized
- ollama's context quantization : for conversation history storage
    - OLLAMA_FLASH_ATTENTION=true
    - OLLAMA_KV_CACHE_TYPE=f16
    - it need not be helpful, experiment reuiqred
- Procedure
    1. start with q4 k_m model 
    2. check for performance and then step up/down

### Resource


### misc

---

## [Install ScrapeGraphAI with LangChain for AI Web Scraping - Turn Website into Structured Data](https://youtu.be/sxlaiNT3yy0)
Release date : Dec 28, 2024
### Idea #spider
- 

### Details
```python
pip install scrapegraphai==0.9.0b7 --upgrade
apt install chromium-chromedriver
pip install nest_asyncio
pip install playwright
playwright install-deps
playwright install

ollama run mistral
ollama run nomic-embed-text

python3
import nest_asyncio
nest_asyncio.apply()

from scrapegraphai.graphs import SmartScraperGraph

graph_config = {
    "llm": {
        "model": "ollama/mistral",
        "temperature": 0,
        "format": "json",  # Ollama needs the format to be specified explicitly
        "base_url": "http://localhost:11434",  # set Ollama URL
    },
    "embeddings": {
        "model": "ollama/nomic-embed-text",
        "base_url": "http://localhost:11434",  # set Ollama URL
    }
}

smart_scraper_graph = SmartScraperGraph(
    prompt="List me all the articles",
    source="https://fahdmirza.com",
    config=graph_config
)

result = smart_scraper_graph.run()
print(result)

```
- needs credit to run
- Has tool call to invoke own api

### Resource


### misc
https://github.com/ScrapeGraphAI/Scrapegraph-ai
---

## [Are your agents specialized enough?](https://youtu.be/9LLoaOsbcNM)
Release date : Dec 27, 2024
### Idea #agents
- 

### Details
Key Aspects  | Key Features | Description
-|-|-|
Agent Creation | Provision, Custom, Spawn & Deploy Autonomous Al Agents | Create production-ready & scalable autonomous agents.
Agent Creation | Extend Agent Capabilities with Toolkits | Add Toolkits from marketplace to agent workflows.
Agent Creation | Extend Agent Capabilities with Multiple Vector DBs | Connect to muluple Vector DBs to enhance agent's performance,
Agent Creation | Extend Agent Capabilities with (fine-tuned) Models | Custom fine-tuned models for business specific use Cases.
Prompt Mgmt | Prompt Versioning and Management | Keep track of different versions of prompts used in agents. Useful for A/B testing and optimizing
Evaluation and Test | Test Agents Against Benchmarks and becnhmarking | Create a dataset; Define metrics; Run Evaluations; ing results; Track results over time etc.
Evaluation and Test | Evaluate Agent in Diverse Steps | Evaluate Evaluate the agent's final response.
Human Interface | Collect Explicit Feedback | Evaluate Single Mep Evaluate any agent step in isolation (¢.g., whether it selects the appropriate lool).Evaluate tajectory Evaluate whether the agent look the expected path (¢.g., of tool calls) to brrive at the final answer.
Human Interface | Collect Implicit Feedback  | Directly prompt the user to give feedback, this tan be a thumb up or a thumb down.
Monitoring | Agent Analytics Dashboard | Measure the user's behavior, this can be time spent on a page, click-through rate. Monitor diverse level and dimension statistics about
Tracing | LLM Cost Management and Tracking | 


### Resource


### misc

---

## [Fine tuning Embeddings Model](https://youtu.be/hdFHYNCmO8U)
Release date : Jun 1, 2024 
### Idea #finetune

This video you will learn
1. Fine tuning embeddings model
2. What types of Data sets can be used
3. How to to test fine tuned embeddings model.


### Details
- For better rag performance
- any embedding model + data + trainig arg + train and test
- get it from sentence embeddings
- in this ex  bge large is being finetuned
- 5k data points into train test val split
- Data strcture
    - anchior : data with query
    - positive answer
    - negative reply
    - or it can be anchor and positive
    - or prmise hypothesis and label
    - or pair score
        - stentence 1 sentence2 similairty score

### Resource
- https://www.sbert.net/docs/sentence_transformer/training_overview.html#dataset
- https://github.com/mosh98/RAG_With_Models/blob/main/Fine-Tune/Fine_tuing_embeddings_model_DEMO.ipynb

### misc
What is sentence transformer?
Sentence Transformers v3.0 introduces significant improvements to the framework for creating and fine-tuning embedding models. This update includes a new training API, backed by `SentenceTransformerTrainer`, enhancing multi-GPU training and detailed loss logging. The version adds new similarity functions like cosine, dot, euclidean, and manhattan, specified via `similarity_fn_name`, for better adaptability to specific tasks Additionally, it supports hyperparameter optimization, extending capabilities from the broader `transformers` library. The release expands loss functions and datasets, ensuring a wide range of training scenarios are covered. While maintaining backward compatibility, the update encourages transitioning to the new API for full benefits.

You can used either BGE or nomic-embed-text model to fine tune your model.

---

## [KAG Framework SMASHES GraphRAG in Accurate Knowledge Generation](https://youtu.be/TnTH85-jobE)
Release date :  Dec 24, 2024
### Idea #RAG
- Knowledge augumented generation

### Details
- Knowledge-Augmented Generation (KAG) combines:
    . Open infromation Extraction (OpenlE)
    - Knowledge Graphs (KGs)
    - Advanced Multi-hop Reasoning
- Index Construction:
    - OpenIE Integration : semantic chukcing, info extraction, alignment = domain know. graph
    - Semantic Graph Building : each chunk will have entities extracted to form a relation graph
    - Knowledge Alignment
- Question-Answering: Resoning, planning, symbolic rep, generation, alignment with KG f/b
    - Logic Symbol-Guided Reasoning
    - Hybrid Retrieval System
    - Document Fallback Strategy
- has UI

### Resource
https://github.com/OpenSPG/KAG
https://arxiv.org/pdf/2409.13731

### misc

---

## [Difference Between Flash Attention, Flash Attention 2 and Duo Attention](https://youtu.be/yz9UVWoP38Y)
Release date : Dec 22, 2024
### Idea #llm
- 

### Details
- Attention calculates weightage given to each token w.r.t others
- for long rage dependencies capturing
- and contextual relation between sequence
- Flash : 
    - i/o aware to address quadratic time and memory complexity in trx using self attention
    - uses styling to reduce memory read and writes between gpu and chip
    - speedsup without reducing performance
    - longer context use
- FLash 2 :
    - optimized
    - for gpu utilizations
    - partitions between thread bloacks and warps
    - 2x speed
    - reducing non matrix multiplicaiton flops
    - parallelzing attention computation
- Duo Attention
    - Framework to reduce memory and latency requirement for deploying long context llm
    - identifyes retrival heads : requires full attention across all tokens
    - identifies straming heads :  focus onrecent tokens
    - uses light weigh, constant lenght kv caching 
    - memoery and latency reduction
    - for liimted hardware

### Resource
https://github.com/Dao-AILab/flash-attention

### misc

---

## [NVIDIA Hymba : The best small LLM](https://youtu.be/d-rKejutpUM)
Release date : Nov 22, 2024
### Idea
- Nvidia's Hymba uses hybrid architecture and is the best small llm

### Details
- combiens self attention, and mamba
- mamba is memory efficient and faster as it overcomes the quadratic input length complexity of llm
- llm has attention heads for specif details
- paralallizable processing of mamba and attention heads
- mean is taken for output
- meta tokens :  has imp info for processing
- cross layer sharing gives efficiency increase
- base 3GB

### Resource


### misc

---

