## [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://youtu.be/I78o3_lxXaQ)
Release date : 
### Idea
- Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking

### Details
- based up on this paper : Think before you speak: Training Language Models With Pause Tokens
- learn reasoning in scalable way
- adpatable and robust llms
- thoughts are used before predicting
- Learning to think in any context
- 

### Resource
- [paper](https://arxiv.org/pdf/2403.09629.pdf)

### misc
 
---
## [LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models](https://youtu.be/7Ti1G4CXB2A)
Release date : 5/4/24
### Idea
- LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models

### Details
- hallucination is a big issue in ViT (vision transf.)
- LVLM interpret is introduced which adpats various interpretability tools
    - raw attention visualization
    - relevancy maps
    - causal graphs interpretation
- ui in gradio
    - upload images
    - ask queries and 
    - make modification to input for probing


### Resource
- [paper](https://arxiv.org/abs//2404.03118)

### misc
 
---
## [SWE-Agent: The New Open Source Software Engineering Agent Takes on DEVIN](https://youtu.be/nrW__jof8pg)
Release date : 03/04/24
### Idea
- deviaka and devin performance checking using SWE-agent
- s/w eng. agent
- swe-becnh for github issues solving 

### Details
- swe-agent-gpt4 is competing with devin
- 93 sec vs devins 5 mins
- open source

### Resource
- SWE-Agent: https://github.com/princeton-nlp/SWE-agent

### misc
 
---
## [How to Jailbreak LLMs - Anthropic Releases Many-shot Jailbreaking](https://youtu.be/VLZKJAyds0o)
Release date : 05/04/24
### Idea
- can by pass guardrails of llms using large context window
- filled with 100s of fake dialog between human and ai asst.
- before question occurs

### Details
- effective on antropic and other llms
- Its like talking a lot and confusing the llm to let go of the restrictions placed on it
- major reason being the long context window and leads to content with
    - Violent-hateful
    - Deception
    - Discrimination
    - Regulated content
- due to incontext learning
- how to prevent it?
    - classification and 
    - modification of the prompt before llm reads it
    - sanitizing ???

### Resource
- [many shot jailbreaking](https://cdn.sanity.io/files/4zrzovbb/website/af5633c94ed2beb282f6a53c595eb437e8e7b630.pdf)

### misc
 
---
## [Mixture-of-Depths - Make AI Models Faster By 50%](https://youtu.be/fjxW4Q_jUdU)
Release date : 05/04/24
### Idea
- 

### Details
- 

### Resource
- [Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](https://arxiv.org/pdf/2404.02258)

### misc
 
---
## [SafeMate, by Cesar Alvarez](https://youtu.be/y-v-1eBltmI)
Release date : 04/04/24
### Idea
- In construction industry there are too many doc to look for saefty
- this can lead to cognitive overload
- one stop location for accessing all the answer can be created using chatbot

### Details
- Measuring Success Through Usage: Empowering Workers with Information They Actually Use
- data : 300 pages of instructions
- gui in huggingface space
- 

### Resource
- [github](https://github.com/cga-telice/mlops-course/tree/main/SafeMate)

### misc
 
---
## [ResearchPaperSimplify, by Anurag Lahon](https://youtu.be/CcHaGlPt_kA)
Release date : 04/04/24
### Idea
- research paper summarizer and chatbot

### Details
- 

### Resource
- [code](https://github.com/anuraglahon16/ResearchPaperSimplify/blob/main/rag_utils.py)

### misc
 
---
