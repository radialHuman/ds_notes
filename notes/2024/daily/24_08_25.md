## [The ONE Thing You need to Code in 2024!!! ðŸ’¥Andrej Karpathy's favorite AI tool ðŸ’¥](https://youtu.be/2ybCIacN9Ns)
Release date : 25/8/24
### Idea
- Ai powered text editor

### Details
- 

### Resource
- https://zed.dev/blog/zed-ai
- https://www.cursor.com/blog/series-a

### misc
 
---
## [Most Businesses are Approaching AI Backwards](https://youtu.be/XSITyCRKvng)
Release date : 24/08/24
### Idea
- companies should forst loook at metrics and goals then problem and then solution, not what can ai do for us

### Details
- top down optimization and prioritization

### Resource
- 

### misc
 
---
## [812: The AI Scientist: Towards Fully Automated, Open-Ended Scientific Discovery â€” with Jon Krohn](https://youtu.be/nFJVDEjoaCA)
Release date : 23/08/24
### Idea
- startup Sakana AI

### Details
- automate scintific discovery using llms 
- generate novel ideas
- design exp
- code exp
- write papers with formatting
- automated reviwers also included
- claude sonet worked the best : also has 4o, llama, and deepseek
- 15$ each paper
- 


### Resource
- 

### misc
 
---
## [Optimize Your AI Models](https://youtu.be/QfFRNF5AhME)
Release date : 23/08/24
### Idea
- Parameteres to choose from while optimizing llms

### Details
- temprature : guess the most likeliy next word, using logistic units, -10 to 10 , using softmax
    - less than 1 : makes bigger numebrs bigger and msaller smaller
    - more than 1 : closer logits and less probable ones become more probabl so more creative
- num_ctx : context size, default is 2k in ollama, as people have small resources
    - edit the paramter in config file to make llm use full potential by providing required context window
- stop : while generating if it gets in a loop and produces one word again and again, to stop that
- repeat_penalty : to make prob of word already use less
- repeat_last_n : window size to look for repeats
- top_k : length of list of words which can be potentially generate
- top_p : add all the probabilites which add up to entered value and have that list
- min_p : takes max prob, and multiplies it by entered value. Selects all probabiolites which are more than that value
- tfs_z : tail free sampling. cut off the list of words which are of very less proability at the tail end
    - 1 : not cutting
    - 0 : all gone
- seed : as usual in ml models
- more ways to come up with next token
    - mirostat : if 0 then above params can be used, if 1 then the following can be used. uses prepexilty (more is creative 0.9)
    - mirostat_tau : balance between coherence and diversity (5.0)
    - mirostat_eta : lerning rate used to adapt (less is stable, while higher is faster to adapt 0.9)
- num_predict : number of words to predict
    - -1 is infinite
    - -2 fill the context


### Resource
- https://github.com/ollama/ollama/blob/main/docs/modelfile.md

### misc
 
---
## [Try this Before RAG. This New Approach Could Save You Thousands!](https://youtu.be/UZg_xyIS9_E)
Release date : 22/08/24
### Idea
- How to use gemini 1.5 better reducing cost

### Details
- 

### Resource
- https://huggingface.co/vidore/colpali
- https://ai.google.dev/gemini-api/docs/document-processing?lang=python
- https://colab.research.google.com/drive/1WA-0da62qBU8ElSclfrzgicFRxxpcBMN?usp=sharing

### misc
 
---
