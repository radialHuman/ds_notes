## [OpenAI CLIP model explained](https://youtu.be/jXD6O93Ptks)
Release date : Jun 4, 2024
### Idea #vision
- self supervised contrastie learnign based on image text pair
- zero shot transfer

### Details
- uses natural language supervision
- as labelled image is scarse while text is easily available
- this combines text and image represenatations which help in several applications
- webimage text : 400M pairs of image and text
- inspired by VirTex and ConVIRT #todo
- virtex is sequential while convirt is parallel text and image understanding
- theyuse contrastive loss to learn
- The goal is to make the representation of the corect pairs similar while of incorrect as far as possible
- Process
    - take text encode it (GPT 2)
    - parallely take image and encode it as well (ResNet or ViT)
    - get the both the emcodings are normalized and a dot product is performed
    - since the output is a square matrix and the diagonals are the correct pair
    - the objective is to make it more simialr than the other parts of the matrix
    - cross entorpy loss is used
-   Experiments
    - zero shot transfer : generalization over unseen data
    - Representation learnign : transfer learnign
    - out of distribution testing
- 

### Resource


### misc

---

## [Create an AI Research Assistant from Scratch Under 2 Hours!](https://youtu.be/762sqd7Iw6Y)
Release date : Jan 9, 2025
### Idea #TODO
- 

### Details
- 

### Resource


### misc

---

## [Large Concept Models (LCMs) by Meta: The Era of AI After LLMs?](https://youtu.be/TwLiNTYvpPo)
Release date :  Jan 4, 2025
### Idea #LCM
- Meta : Humans dont generate tokens but image concepts so the same can be done using transformers

### Details
- Usually a transformer starts by tokenizing words
- which divides the words into byte pair or subwords
- and then use it to produce the response
- Replaces tokens with concepts
- Idea:
    - concept : represntation of higher level ideas or action, not language specific or modal 
    - can overcome the large context input by reducing words to concepts
    - this leads to better hierarchical reasoning
- concepts are represented in the embedding space rather than words
- Architecture
    - SONAR words are passed through concept encoder which convetrs them into concerpts embeddings #TODO
        - ITS FIXED and supports 200 languages and 76 speech input too
    - This is passed to LCM to generate output in the conceprt representation space
    - This is language and modal agnostic
    - Then the output is decoded into words using SONAR
- JEPA #doubt
- Base LCM
    - predicts next concept in the concept space
    - MSE is sued to calculate the error while self-supervised elarning
    - using Pre-net -> trx decoder -> post net
    - pre-net : normalizes input from SONAR and maps them into trx's dimenstion
    - post net : projects into SONAR's dimensions
    - Problem : one concept can be followed by many others that makes sense
    - so this is not that useful
- This problem is simialr to that in image generation as one description have have multiple image representing it
- They solved it using Diffusion model
    - In diffusion, as noisy random image is taken and based on the prompt, noise is erased to get the final output as in the prompt in multiple 100s steps
- Diffusion based LCM
    - One tower LCM
        - In this the conepts are passed to decoder with last concept having noise and the training finds out how to denoise the concept to be predicted
        - This is done iteratively
    - Two-tower LCM
        - In this the clean concepts are passed through the trx decoder and the noise last concept is passed seperatly into denoise section
        - This consists of Trx layer with corss attention block to get input from cleanc oncepts decocded and does the denoising accordingly #doubt
- There are other architectures like Quant LCM #TODO

### Resource
 https://arxiv.org/abs/2412.08821
 https://github.com/facebookresearch/large_concept_model
 https://aipapersacademy.com/i-jepa-a-human-like-computer-vision-model/
 https://aipapersacademy.com/v-jepa/

### misc

---

## [Meta Large Concept Models (LCMs)](https://youtu.be/GY-UGAsRF2g)
Release date : Jan 6, 2025
### Idea
- Sentence prediction/ concept prediction instead of token
- good for long form, model agnostic and laguage independent output

### Details
- Its trained on image text and videos
- which gives them a complete understanding of a concept
- This helps with understanding of the flow of ideas and not just the language
- Process
    - input words are segmented into sentences
    - then encoded using fixed size embedding
    - using pre-trained sentence encoder SONAR
    - The generated concetp is again decoded to text or image what ever was the expected output
- Based on diffusion and quantized model
- better at geenralizing multimodal

### Resource


### misc

---


