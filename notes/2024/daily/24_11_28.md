## [Revolutionize Document Retrieval with THIS Vision Language Model Hack](https://youtu.be/ku6kof8bwbw)
Release date : Nov 28, 2024
### Idea
- Colpali for pdfs with vision laguage for text image table extraction

### Details
- doc retrival :
    - matching query to documents in corpus
    - this is core of RAG
    - handleing complex data is a challenge and scaling it too while maintining performance
- tradiaitonal text search used tfidf or BM25 (string matching, fast)
- doesn understand the layout and visual context
- bi encoders were better but slower and only textual
- OCR layout, image capturing is all different task need to be chained
- for multi type data in pdf
    - use vision laguage model
- COlpali
    - colbert : late interaction tech (for better query processing)
    - paligemma : google's VLM
    - pdf converted to image and process
    - First colpali breaks input into images and embeds and the another LLM will udnerstand and answer the query
    - faster than normal OCR
- Mechanism
    - Each page is divided into small patches
    - pass them to vision encoder model
    - this will vectorize them and sent to projection layer for dimension change
    - then pass these embeddings to LLM
    - the output of which will gain go through projecttion layer to reduce the length of embedding
    - These ares tored in VDB
    - Later, when the Query  arrives, it passes through vision encoder to get enbedidngd
    - each token of the embedding is compared with the VDB vectors using MaxSIm 
    - Retrival will be patches which will be stiched together ??? then do ocr on it?
    - VIsion Encoder : SigLIP (better clip)
    - LLM : Gemma 2B
    - Query LLM  : Gemini FLash


### Resource
-  (https://arxiv.org/abs/2407.01449) 
-  (https://arxiv.org/abs/2407.07726)

### misc
 
---