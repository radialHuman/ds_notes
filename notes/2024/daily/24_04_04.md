## [AutoQuant - Quantize Any Model in GGUF AWQ EXL2 HQQ](https://youtu.be/sppdPLaiqZo)
Release date : 
### Idea
- AutoQuant by Maxime Labonne which allows you to quantize your models in five different formats:
    - GGUF: perfect for inference on CPUs (and LM Studio)
    - GPTQ/EXL2: fast inference on GPUs
    - AWQ: super fast inference on GPUs with vLLM
    - HQQ: extreme quantization with decent 2-bit and 3-bit models

### Details
- Code explanation

### Resource
- [code](https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing#scrollTo=OE_R3AXG5Y-F)

### misc
 
---
## [The State of AI Engineering Jobs in 2024](https://youtu.be/DcmJ8_H5xD0)
Release date : 
### Idea
- 

### Details
- 

### Resource
- [laura's github to follow](https://github.com/lfunderburk?tab=repositories)
- [Haystack](https://github.com/deepset-ai)

### misc
 
---
