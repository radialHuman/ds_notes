sno. | link | title | descp | status | md
-|-|-|-| -|-|
1| [link](https://www.youtube.com/watch?v=mEsleV16qdo) | Generative AI Full Course ‚Äì Gemini Pro, OpenAI, Llama, Langchain, Pinecone, Vector | Not great| rewatch as intro | [notes](genAI_30.md)
2| [LC playlist](https://www.youtube.com/playlist?list=PL8motc6AQftk1Bs42EW45kwYbyJ4jOdiZ) |LangChain How to and guides |  | WIP | [notes](langchainplaylist.md)
3| [playlist](https://www.youtube.com/playlist?list=PLmsFUfdnGr3zAgBMu4l1W713a0W__zAMl) | Generative AI for Beginners | just and intro | DONE | [notes](gen_beginners.md)
4| [aws bedrock](https://www.youtube.com/watch?v=2maPaQutcWs) | Generative AI In AWS-AWS Bedrock Crash Course  | just a glance | DONE | [notes](bedrock.md)
5 | [langchain](https://www.youtube.com/watch?v=aWKrL4z5H6w)| Complete Langchain GEN AI Crash Course With 6 End To End LLM Projects With OPENAI,LLAMA2,Gemini Pro | long one | useless | [notes](langchain.md)
6 | [from scratch playlist](https://www.youtube.com/playlist?list=PLhr1KZpdzukf-xb0lmiU3G89GJXaDbAIF) | Generative AI Foundations on AWS Technical Deep Dive Series | basics, some imp noteboooks, skipping last 4 as tey are too much | DONE | [notes](aws_genai.md)
7 | [gradient ai](https://youtu.be/_78rA4uV4jA) | How To Fine Tune LLAMA2 LLM Models With Custom Data |  | TODO | [notes]()
8 | [fine tuning playlist](https://youtu.be/Vg3dS-NLUT4) | Steps By Step Tutorial To Fine Tune LLAMA 2 With Custom Dataset Using LoRA And QLoRA Techniques | useful intro to lora | DONE | [notes](fine_tuning_lora_qlora.md)
9 | [gradient ai](https://youtu.be/_78rA4uV4jA) | How To Fine Tune LLAMA2 LLM Models With Custom Data |  | TODO | [notes]()
10 | [fine tuning playlist](https://www.youtube.com/playlist?list=PLrLEqwuz-mRIEtuUEN8sse2XyksKNN4Om) |Fine Tuning of LLMs |  | TODO | [notes]()
11 | [shaw](https://youtu.be/eC6Hd1hFvos) | Fine-tuning Large Language Models (LLMs)  w/ Example Code |  | TODO | [notes]()
12 | [peft](https://youtu.be/Us5ZFp16PaU) | Fine-tuning LLMs with PEFT and LoRA |  | DONE | [notes](peft_and_lora.md)
13 | [single cpu qlora](https://youtu.be/MDA3LUKNl1E) | Fine-tuning Llama 2 on Your Own Dataset  Train an LLM for Your Use Case with QLoRA on a Single GPU |  | TODO | [notes]()
14 | [sieseme pytorch](https://youtu.be/zvk3Rr-OjU0) | Seismic Data to Subsurface Models with OpenFWI: Training an AI Model with PyTorch |  | TODO | [notes]()
15 | [shaw single cpu](https://youtu.be/XpoKB3usmKc) | QLoRA‚ÄîHow to Fine-tune an LLM on a Single GPU (w/ Python Code) |  | TODO | [notes]()
16 | [mixtral](https://youtu.be/RzSDdosu_y8) | Fine-tune Mixtral 8x7B (MoE) on Custom Data - Step by Step Guide |  | WIP | [notes]()
17 | [rag llama](https://youtu.be/Y0FL7BcSigI) | A deep dive into Retrieval-Augmented Generation with Llamaindex | | TODO | [notes]() 
18 | [mastering LlamaIndex](https://youtu.be/XGBQ_f-Yy48) | Mastering LlamaIndex : Create, Save & Load Indexes, Customize LLMs, Prompts & Embeddings | | TODO | [notes]() 
19 | [vector store](https://youtu.be/Cu5KQz3c4Zk) | RAG with Llama-Index: Vector Stores | | TODO | [notes]() 
20 | [gpt3.5](https://youtu.be/WKvAWub8VCU) | Llama Index 101 with Vector DBs and GPT 3.5 | | TODO | [notes]() 
21 | [llamaparser](https://youtu.be/wRMnHbiz5ck) | Super Easy Way To Parse PDF | | TODO | [notes]() 
22 | [llamaindex 0.1](https://youtu.be/swJsw9Jvgoc) | Introduction to LlamaIndex v0.10 | | TODO | [notes]() 
23 | [e2e](https://youtu.be/hH4WkgILUD4) | End to end RAG LLM App Using Llamaindex | | TODO | [notes]() 
24 | [own copilot](https://youtu.be/gszpdJxAWs4) | Create your own Copilot using Semantic Kernel (Reactor series- GenAI for software developers) | | TODO | [notes]() 
25 | [semantic beginner](https://youtu.be/ku3jEkjC09A) | Semantic Kernel for Beginners: Exploring the World of Semantic Kernel | | TODO | [notes]() 
26 | [SK, LC, PF compare](https://youtu.be/D34PyNx71vk) | Where does SK fit in the AI ecosystem? | | TODO | [notes]() 
27 | [Advanced Search](https://youtu.be/JEBDfGqrAUA) | Vector Search RAG Tutorial  | | TODO | [notes]() 
28 | [chose VDB](https://youtu.be/aX_hdQEintc) | How to Choose a Vector Database | | TODO | [notes]() 
29 | [crash VDB](https://youtu.be/ySus5ZS0b94) | OpenAI Embeddings and Vector Databases Crash Course | | TODO | [notes]() 
30 | [open vs openai](https://youtu.be/QdDoFfkVkcw) | $0 Embeddings (OpenAI vs. free & open source) | | CANCELLED | [notes]() 
31 | [fcc tutorial](https://youtu.be/yfHHvmaMkcA) | Vector Embeddings Tutorial ‚Äì Code Your Own AI Assistant with GPT-4 API + LangChain + NLP | | TODO | [notes]() 
32 | [VD 101](https://youtu.be/6yLmbL1o3Ow) | Vector Database 101: A Crash Course| | TODO | [notes]() 
33 | [high perf RAG](https://youtu.be/wBhY-7B2jdY) | High-performance RAG with LlamaIndex | | TODO | [notes]() 
34 | [chroma 1](https://youtu.be/eCCHDxMaFIk) | Semantic Search with Open-Source Vector DB: Chroma DB  Pinecone Alternative | | TODO | [notes]() 
35 | [chroma 2](https://youtu.be/QSW2L8dkaZk) | Getting Started with ChromaDB - Lowest Learning Curve Vector Database & Semantic Search | | TODO | [notes]() 
36 | [chroma 3](https://youtu.be/61kaK-e3Owc) | How to run a private Chroma Vector Database locally in 5 mins! | | TODO | [notes]() 
37 | [VDB](https://youtu.be/8KrTO9bS91s) | Complete Tutorial on Vector Database - Learn ChromaDB, Pinecone & Weaviate | code explanation | WIP | [notes]() 
38 | [langchain playlist](https://www.youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5) | LangChain | | TODO | [notes]() 
39 | [milvus 1](https://youtu.be/612Y0jXmWKk) | End to end Demo | | TODO | [notes]() 
40 | [milvus 2](https://youtu.be/ZABs7HcMPR0) | Milvus 101- Most Advanced Vector Database  | | TODO | [notes]() 
41 | [milvus 3](https://youtu.be/kIj-KKnC-PA) | Milvus: A Purpose-Built Vector Data Management System! (Li Liu) | | TODO | [notes]() 
42 | [weaviate 1](https://youtu.be/7AGj4Td5Lgw) | Weaviate + LangChain for LLM apps presented by Erika Cardenas | | TODO | [notes]() 
43 | [faiss 1](https://youtu.be/ZCSsIkyCZk4) | FAISS Vector Library with LangChain and OpenAI (Semantic Search) | | TODO | [notes]() 
44 | [compare VBD](https://youtu.be/zGAkhN1YZXM) | Langchain VectorStores Show Down | | TODO | [notes]() 
45 | [compare VDB](https://youtu.be/b9f9MZBqfD8) | Vector Databases with FAISS, Chromadb, and Pinecone: A comprehensive guide | | TODO | [notes]() 
46 | [langchain FCC](https://youtu.be/lG7Uxts9SXs) | LangChain Crash Course for Beginners | | TODO | [notes]() 
47 | [lang vs index](https://youtu.be/nze2ZFj7FCk) | Langchain vs Llama-Index - The Best RAG framework? (8 techniques) | | TODO | [notes]() 
48 | [lang vs index](https://youtu.be/EoauGRf_VCA) | Langchain vs Llama-Index| | TODO | [notes]() 
49 | [llamaindex playlist](https://www.youtube.com/playlist?list=PLZoTAELRMXVNOWh1SDXt5NFujQMOt-CWy) | LLamaindex | | WIP | [notes](llamaindex_playlist.md) 
50 | [bedrock end 2 end](https://www.youtube.com/watch?v=0LE5XrxGvbo) | aws bedrock | | WIP | [notes](bedrock_playlist.md) 
51 | [langchain playlist](https://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar) | langchain | | WIP | [notes](langchain_playlist.md) 
52 | [langserver 1](https://youtu.be/FgTYqJVNdkU) | Deploy LLM App as API Using Langserve Langchain  | Just an intro | DONE | [notes](langserve.md)
53 | [langsmith 1](https://youtu.be/3Gcm27l-uyQ) |  Langsmith LLMOPS Platform By Langchain-Debug ,Monitor And Build Production Grade LLM Application | just an intro | DONE | [notes](langsmith.md)
54 | [interview](https://www.youtube.com/watch?v=UifWm9h96Ec) |  | | DONE | [notes](interview.md) 
55 | [llama2 SM HF](https://www.youtube.com/watch?v=Kq597DYdMEE&pp=ygURZGVwbG95IGxsbSBpbiBhd3M%3D) | Launch your own LLM (Deploy LLaMA 2 on Amazon SageMaker with Hugging Face Deep Learning Containers) |  | TODO | [notes]()
56 | [SM DLC LLM](https://www.youtube.com/watch?v=A9Pu4xg-Nas&pp=ygURZGVwbG95IGxsbSBpbiBhd3M%3D) | Deploy LLMs (Large Language Models) on AWS SageMaker using DLC |  | TODO | [notes]()
57 | [Bedrock AWS](https://www.youtube.com/watch?v=jzIZcgaTruA&pp=ygUNIGF3cyAgYmVkcm9jaw%3D%3D) | AWS re:Invent 2023 - Build your first generative AI application with Amazon Bedrock (AIM218) |  | TODO | [notes]()
58 | [genai bedrock AWS](https://www.youtube.com/watch?v=vleGSQ_mIvc&pp=ygUNIGF3cyAgYmVkcm9jaw%3D%3D) | AWS re:Invent 2023 - Accelerate generative AI application development with Amazon Bedrock (AIM337) |  | TODO | [notes]()
59 | [training llm](https://www.youtube.com/watch?v=i9MiLFMTmfI&pp=ygUQbWxvcHMgY29tbXVuaXR5IA%3D%3D) | Art and Science training LLMs |  | TODO | [notes]()
60 | [read paper](https://www.youtube.com/watch?v=K6Wui3mn-uI) | Read AI research paper |  | TODO | [notes]()
61 | [Prod LLM](https://www.youtube.com/watch?v=fo0F-DAum7E) | Prod LLM  |  | TODO | [notes]()
62 | [RAG step/step](https://www.youtube.com/watch?v=qN_2fnOPY-M&pp=ygUYcmFnIHNjcmF0Y2ggc3RlcCBieSBzdGVw) | Local Retrieval Augmented Generation (RAG) from Scratch (step by step tutorial) |  | TODO | [notes]()
63 | [DL channel](https://www.youtube.com/@Deeplearningai/streams) | DeepLearning |  | TODO | [notes]()
64 | [LangChain Channel](https://www.youtube.com/@LangChain/videos) | LangChain |  | TODO | [notes]()
65 | [LLM 5 formula](https://www.youtube.com/watch?v=k9DnQPrfJQs&pp=ygUTNSBmb3JtdWxhIHRyYWluIGxsbQ%3D%3D) | LLMs in 5 formula |  | TODO | [notes]()
66 | [Vector DB](https://www.youtube.com/watch?v=9iou9s0L8Fs&pp=ygUSemlsbGlzIHJvdW5kdGFibGUn) | Zilliz Roundtable // Why Purpose-built Vector Databases Matter for Your Use Case |  | TODO | [notes]()
67 | [Finetune playlist](https://www.youtube.com/playlist?list=PLrLEqwuz-mRIEtuUEN8sse2XyksKNN4Om) | Finetuning playlist |  | WIP | [notes](finetune_playlist.md)
68 | [DistillBert Playlist](https://www.youtube.com/playlist?list=PLc2rvfiptPSTGfTp0nhC71ksTY1p5ooCW) | DistilBert |  | TODO | [notes]()
69 | [prompt eng.](https://www.youtube.com/watch?v=RASh7C9Pm7I) | Prompt Enginerring |  | TODO | [notes]()
70 | [Trans4mrs](https://youtu.be/bCz4OMemCcA) | Transformers |  | TODO | [notes]()
71 | [AK GPT](https://youtu.be/kCc8FmEb1nY) | GPT from scratch | Not exactly explaning how Transformers work | WIP | [notes]()
72 | [Chainlit](https://youtu.be/AzfV0r2O_gk) | Chainlit |  | TODO | [notes]()
73 | [Flacon LLM](https://youtu.be/gnyUUY8X-G4) | Falcon LLM |  | TODO | [notes]()
74 | [usecase](https://www.youtube.com/watch?v=MeyVptCRubI) | Solving Real-World Data Science Problems with LLMs! (Historical Document Analysis) | | TODO | [notes]() 
75 | [](https://youtu.be/g84uWgVXVYg) |  |  | TODO | [notes]()
76 | [chunk size](https://www.youtube.com/watch?OBttxJ6FTBE) |  | JS based, not required | WIP | [notes]()
77 | [mistral 7b local FT](https://www.youtube.com/watch?Wqf2GimAlWo) |  |  | TODO | [notes]()
78 | [llama factory](https://www.youtube.com/watch?iMD7ba1hHgw) |  |  | TODO | [notes]()
79 | [FT](https://www.youtube.com/watch?eC6Hd1hFvos) |  |  | TODO | [notes]()
80 | [Qlora FT](https://www.youtube.com/watch?XpoKB3usmKc) |  |  | TODO | [notes]()
81 | [deploy ai models](https://www.youtube.com/playlist?list=PLrLEqwuz-mRKB0Ye9V-NuGASYApagRneg) |  |  | TODO | [notes]()
82 | [lora and qlora in depth](https://youtu.be/t1caDsMzWBk) | Low-rank Adaptation: LoRA Fine-tuning & QLoRA Explained In-Depth | | WIP | [notes]()
83 | [lora+, dora neft unsloth intro](https://youtu.be/ae2lbmtTY5A) | Fine tuning Optimizations - DoRA, NEFT, LoRA+, Unsloth |  | DONE | [notes](lora_dora_neft_unsloth.md) 
84 | [dpo alignment](https://youtu.be/QXVCqtAZAn4) | Aligning LLMs with Direct Preference Optimization | Really interesting | DONE | [notes](dpo_alignment.md) 
85 | [a-z prompt](https://youtu.be/QYs90ps6rxk) | The A to Z of Prompt Engineering - Intro to Prompt Engineering | | DONE | [notes](a_z_prompt.md) 
86 | [basic qlora code walkthrough](https://youtu.be/j13jT2iQKOw) | Fine-tuning LLMs with Hugging Face SFT üöÄ  QLoRA LLMOps | | DONE | [notes](finetuning.md) 
87 | [stanford RAG](https://youtu.be/mE7IDf2SmJg) | Stanford CS25: V3 I Retrieval Augmented Language Models | advanced stuff | DONE | [notes](stan_rag.md) 
88 | [colbertv2](https://youtu.be/xTzUn3G9YA0) | Supercharge Your RAG with Contextualized Late Interactions | | DONE | [notes](colbertv2.md) 
89 | [course CF]() | AWS CloudFormation - Simplified  Hands On with YAML | | TODO | [notes](aws_cloudformation__simplified__hands_on_with_yaml.md) 
90 | [course bedrock]() | Amazon Bedrock and AWS Generative AI - Beginner to Advanced | | TODO | [notes](amazon_bedrock_and_aws_generative_ai__beginner_to_advanced.md) 
91 | [course bedrock]() | Udemy - Amazon Bedrock - Hands On Training for Generative AI | | TODO | [notes](udemy__amazon_bedrock__hands_on_training_for_generative_ai.md) 
92 | [course bedrock]() | Udemy - Amazon Bedrock Masterclass - The Ultimate Generative Ai Guide | | TODO | [notes](udemy__amazon_bedrock_masterclass__the_ultimate_generative_ai_guide.md) 
93 | [course llamaindex]() | Udemy - LlamaIndex- Develop LLM powered applications with LlamaIndex | | TODO | [notes](udemy__llamaindex_develop_llm_powered_applications_with_llamaindex.md) 
94 | [course langchain]() | Udemy - Mastering Langchain And Aws - A Guide To Economic Analysis | | TODO | [notes](udemy__mastering_langchain_and_aws__a_guide_to_economic_analysis.md) 
95 | [course CF]() | Co-Udemy-AWS CloudFormation Master Class v2 [2022] | | TODO | [notes](coudemyaws_cloudformation_master_class_v2_2022.md) 
96 | [course langchain]() | LangChain MasterClass-Develop 7 OpenAI LLM Apps using Python | | TODO | [notes](langchain_masterclass_develop_7_openai_llm_apps_using_python.md) 
97 | [course CF]() | Linkedin - Advanced AWS CloudFormation for Enterprise | | WIP | [notes](linkedin__advanced_aws_cloudformation_for_enterprise.md) 
98 | [course CF]() | Udemy - AWS CloudFormation Step By Step Beginner to Intermediate | | WIP | [notes](udemy__aws_cloudformation_step_by_step_beginner_to_intermediate.md) 
99 | [Semantic Chunking](https://youtu.be/dt1Iobn_Hw0) | Semantic Chunking for RAG | | DONE | [notes](semantic_chuncking.md) 
100 | [ORPO](https://youtu.be/OWMJ0rBUj04) | Combined Preference and Supervised Fine Tuning with ORPO | Nice details | DONE | [notes](orpo_1.md) 
101 | [orpo](https://youtu.be/6kkJGkPZP88) | ORPO: NEW DPO Alignment and SFT Method for LLM |  | DONE | [notes](orpo_2.md) 
102 | [Sparse and Dense Embeddings](https://youtu.be/6_Tjdu6IZdA) | Exploring Sparse and Dense Embeddings: A Guide for Effective Information Retrieval with Milvus | | TODO | [notes]( sparse_dense_embed.md) 
103 | [5 levels](https://youtu.be/8OJC21T2SL4) | The 5 Levels Of Text Splitting For Retrieval | important stuff | DONE | [notes](5_chunking.md) 
104 | [llm with Qlora](https://youtu.be/9Ieaf42tOnw) | Webinar: How to Fine-Tune LLMs with QLoRA | | DONE | [notes](decillm_qlora.md) 
105 | [Updated Langchain](https://www.youtube.com/playlist?list=PLZoTAELRMXVOQPRG7VAuHL--y97opD5GQ) | langchain ecosystem | | TODO | [notes](lang_chain_eco.md) 
106 | [colbert](https://youtu.be/kEgeegk9iqo) | Advanced RAG with ColBERT in LangChain and LlamaIndex | | TODO | [notes](colbert_lang_llama.md) 
107 | [lisa](https://youtu.be/BYZ7H9JR9mU) | LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning | | WIP | [notes]() 
108 | [dspy](https://youtu.be/NoaDWKHdkH) | DSPy: Transforming Language Model Calls into Smart Pipelines | round about way of explaning | TODO | [notes](dspy_1.md) 
109 | [struggles of llms](https://youtu.be/bYiGlr777hg) | Long-context LLMs Struggle with Long In-context Learning | | DONE | [notes](llm_struggles.md)
110 | [updated LC KN](https://www.youtube.com/playlist?list=PLZoTAELRMXVOQPRG7VAuHL--y97opD5GQ) | Updated Langchain | | WIP | [notes](updated_lang.md) 
111 | [open llm alignment](https://youtu.be/uzxd7WUuWVM) | Advancing LLM Reasoning Generalists with Preference Trees| | WIP | [notes](advance_tree.md) 
112 | [superhuman rag](https://youtu.be/bek8AGvt7dg) | SUPERHUMAN RAG | | TODO | [notes](superhuman.md) 
113 | [semantic cache](https://youtu.be/z4MKqZtV7T4) | RAG Production Trick - Semantic Cache  | | DONE | [notes](semantic_cache.md) 
114 | [Techniques LLMs](https://youtu.be/ahnGLM-RC1Y) | A Survey of Techniques for Maximizing LLM Performance | | DONE | [notes](openai_tech.md) 
115 | [command r+](https://youtu.be/aRHl-XS6Za0) | Cohere's Command-R+ Specialized Model for RAG and Tools | | WIP | [notes](command_r+.md) 
116 | [GPTQ vs. GGUF vs. AWQ](https://youtu.be/mNE_d-C82lI) | Which Quantization Method is Right for You?  | | WIP | [notes]() 
117 | [fastapi model](https://youtu.be/5PgqzVG9SCk) | Creating APIs For Machine Learning Models with FastAPI | html+python+js | WIP | [notes]() 
118 | [llmops](https://youtu.be/K2GAL2ZOgBk) | Charting LLMOps Odyssey // Yinxi Zhang  | | WIP | [notes]() 
119 | [local llm search](https://youtu.be/lsp4KhLETTY) | I found this STUNNING Local Perplexity CLONE!!! | ollama interesting | WIP | [notes]() 
120 | [GPTQ, GGUF](https://youtu.be/YEVyupJxt1Q) | New Tutorial on LLM Quantization w/ QLoRA, GPTQ and Llamacpp, LLama 2 | detailed GGUF | WIP | [notes]() 
121 | [pydantic intro](https://youtu.be/XIdQ6gO3Anc) | Pydantic Tutorial ‚Ä¢ Solving Python's Biggest Problem | | WIP | [notes]() 
122 | [pydantic intro](https://youtu.be/Nlhp4EmE55I) | Does Pydantic Replace Dataclasses in Python? | more hands on than previous | WIP | [notes]() 
123 | [pydantic v2](https://youtu.be/ok8bF8M7gjk) | Pydantic (V2) - In-depth Starter Guide | | WIP | [notes]() 
124 | [dspy intro](https://youtu.be/f_7oLIF6X9o) | Getting started with DSPy tutorial | in detail | WIP | [notes]() 
125 | [pissa](https://youtu.be/lsZ2d363OkA) | PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models | | WIP | [notes](pissa.md) 
126 | [MoE architecture](https://youtu.be/OqlNmNylE0I) | Mixture of Experts: Mixtral 8x7B Dive in | | WIP | [notes]() 
127 | [hyde intro](https://youtu.be/v_BnBEubv58) | Advanced RAG 05 - HyDE - Hypothetical Document Embeddings | | WIP | [notes](hyde.md) 
128 | [2024 mlops state](https://youtu.be/6s9Y5fgP3dg) | The State of Production Machine Learning in 2024 // Alejandro Saucedo // AI in Production | | WIP | [notes](mlops_state.md) 
129 | [ai agents](https://youtu.be/GZWFLEj0UqI) | AI Agents! Giving Reasoning and Tools to LLMs - Context & Code Examples | | WIP | [notes]() 
130 | [sagemaker studio](https://youtu.be/stB-F6jswno) | AWS re:Invent 2023 - Scale complete ML development with Amazon SageMaker Studio (AIM325) | important stuff | WIP | [notes]() 
131 | [rag disadvantage](https://youtu.be/NSTRus2Cen4) | WHY Retrieval Augmented Generation (RAG) is OVERRATED! | | WIP | [notes]() 
132 | [aws bedrock customize](https://youtu.be/YY9N7sDoP30) | AWS re:Invent 2023 - Customize FMs for generative AI applications with Amazon Bedrock (AIM247) | | WIP | [notes]() 
133 | [LLoCO](https://youtu.be/cj05AggcyLY) | LLoCO: Learning Long Contexts Offline | | WIP | [notes](lloco1.md) 
134 | [Rho-1 1](https://youtu.be/2BN7qrAe0Nc) | RHO-1: Not All Tokens Are What You Need | | WIP | [notes]() 
135 | [genai tech](https://youtu.be/CK9dN0KpvGM) | Pre-train Mixtral MoE model on SageMaker HyperPod + SLURM + Fine-Tuning + Continued Pre-Training | | WIP | [notes]() 
136 | [bedrock aws](https://youtu.be/kzzlchi0DzU) | AWS re:Invent 2023 - Building an AWS solutions architect agent with Amazon Bedrock (BOA306) | | WIP | [notes]() 
137 | [5 types of chunking](https://youtu.be/pIGRwMjhMaQ) | Chunking Strategies in RAG: Optimising Data for Advanced AI Responses | | WIP | [notes]() 
138 | [dno intro](https://youtu.be/wRZ8t9NQnac) | Direct Nash Optimization of LLM Beats DPO | | WIP | [notes]() 
139 | [xlstm paper](https://youtu.be/CiOsdnhQumc) | xLSTM Models Might Beat Transformer LLMs | | WIP | [notes]() 
140 | [nemo](https://youtu.be/3DfV6URqrZA) | NeMo Guardrails - Tame your LLM without Prompt Engineering | intro | WIP | [notes](birla) 
141 | [llm avalange](https://youtu.be/mspA9SUgjYw?list=TLPQMTEwNTIwMjTwlt8Pr6OjTA) | LLM Avalanch: Shreya Rajpal: Practical Guardrails for your AI applications | | WIP | [notes](birla) 
142 | [new summarize](https://youtu.be/6Yd6NdJrn4s) | New Summarization via In Context Learning with a New Class of Models | | WIP | [notes](birla) 
143 | [aws guardrails](https://www.youtube.com/watch?v=gIul8qZyA1A) | Build gen AI applications responsibly with Guardrails for Amazon Bedrock  Amazon Web Services | | WIP | [notes](birla) 
144 | [llamaindex prod](https://youtu.be/WLKRAzORtOI) | Practical Data Considerations for Building Production-Ready LLM Applications | | WIP | [notes](birla) 
145 | [learn guardrails](https://youtu.be/XKDcOi-rZ_I) | Learn to Implement Guardrails in Generative AI Applications | | WIP | [notes](birla) 
146 | [nemo code](https://youtu.be/SwqusllMCnE) | NVIDIA NeMo Guardrails: Full Walkthrough for Chatbots / AI | | WIP | [notes]() 
147 | [reranker](https://youtu.be/Uh9bYiVrW_s) | RAG But Better: Rerankers with Cohere AI | | WIP | [notes](birla) 
148 | [citation](https://youtu.be/RnCuOL-LBAw) | Unlocking Advanced RAG: Citations and Attributions | | WIP | [notes]() 
149 | [llmops issues](https://youtu.be/L4tFxMWFVFc) | LLMOps and GenAI at Enterprise Scale - Challenges and Opportunities // Andy McMahon // AI in Prod | | WIP | [notes](birla) 
150 | [llmops thinsg to remember](https://youtu.be/En78C8eXWv8) |  | | WIP | [notes](birla) 
151 | [llm things to remeber while building](https://youtu.be/v21fCCuVMQg) | Lessons from Building LLM-based Social Media Products // Faizaan Charania // AI in Production | | WIP | [notes]() 
152 | [mvp to prod llm](https://youtu.be/Smq3Q9r-9cg) | From MVP to Production // Day 2 Panel 2 // AI in Production Conference | | WIP | [notes]() 
153 | [Prompt Engineering Techniques](https://youtu.be/RASh7C9Pm7I) | Prompt Engineering Techniques (extended version) | | WIP | [notes](birla) 
154 | [giskard intro](https://youtu.be/KeY6qPAvyq0) | Testing Framework Giskard for LLM and RAG Evaluation (Bias, Hallucination, and More) | | WIP | [notes](birla) 
155 | [vectara hallucination](https://youtu.be/O-VYDADgc68) | Check Hallucination of LLMs and RAGs using Open Source Evaluation Model by Vectara | | WIP | [notes](birla) 
156 | [WEAT](https://youtu.be/eTenkUPsjko) | Evaluating Biases in LLMs using WEAT and Demographic Diversity Analysis | | WIP | [notes](biral) 
157 | [pheonix](https://www.youtube.com/watch?v=LrMguHcbpO8) | RAG Time! Evaluate RAG with LLM Evals and Benchmarking | | WIP | [notes](birla) 
158 | [ragas intro](https://youtu.be/5fp6e5nhJRk) | RAGAS: How to Evaluate a RAG Application Like a Pro for Beginners | | WIP | [notes](birla) 
159 | [prometheus intro](https://youtu.be/YJ_jDZPj4V4) | Evaluate LLMs with Prometheus LLM and Prometheus-Eval Locally | | WIP | [notes](birla) 
160 | [prometheus 2 paper](https://youtu.be/KazKtXi4jSM) | PROMETHEUS 2: An Open Source Language Model Specialized in Evaluating Other Language Models | | WIP | [notes](birla) 
161 | [CRAG Paper](https://youtu.be/Har-Pzwx_8I) | Production RAG Must-have: Corrective RAG (CRAG) | | WIP | [notes](birla) 
162 | [langchain eval](https://www.youtube.com/playlist?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S) | LangSmith Evaluations | | WIP | [notes](birla) 
163 | [langSmith eval playlist](https://www.youtube.com/playlist?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S) | LangSmith Evaluation | | WIP | [notes](birla) 
164 | [issue with llm](https://youtu.be/e8vg1vin78U) | Thomas Dietterich, "What‚Äôs Wrong with Large Language Models, and What We Should Be Building Instead" | | WIP | [notes]() 
165 | [scrape ai](https://youtu.be/QxHE4af5BQE) | How to scrape the web for LLM in 2024: Jina AI (Reader API), Mendable (firecrawl) and Scrapegraph-ai | | WIP | [notes]() 
166 | [Quantized Aware training QAT](https://youtu.be/gZYt3F3Aw-E) | Custom Gradient Estimators are Straight-Through Estimators in Disguise | | WIP | [notes]() 
167 | [scrapegraph](https://youtu.be/zDqAZOiPX_M) | Web Scraping AI AGENT, that absolutely works üòç | | WIP | [notes]() 
168 | [evaluation llm](https://youtu.be/rzbwqme61KE) | Evaluating Language Models // Matthew Sharp // AI in Production Conference Lightning Talk | | WIP | [notes]() 
169 | [ai in govt](https://youtu.be/CT21h9fU6V8) | AI Systems in Government: Challenges & Opportunities - Jared Dunnmon  Stanford MLSys#100 | | WIP | [notes]() 
170 | [llmops stack](https://youtu.be/OiyP8uUI1OU) | Navigating the Emerging LLMOps Stack // Hien Luu // AI in Production Conference Lightning Talk | | WIP | [notes]() 
171 | [AGILE Agent](https://youtu.be/F-OQ9bQp3jk) | AGILE: A Novel Framework of LLM Agents | | WIP | [notes]() 
172 | [grph rag](https://youtu.be/vMBL2nErmQ8) | Get Ahead in Your RAG! Must-Know Knowledge Graph Integration Secrets! | | WIP | [notes]() 
173 | [buffer of thought](https://www.youtube.com/watch?v=gCGck5Fn3G4) | New prompting method uses thought templates | Buffer of Thoughts | | WIP | [notes]() 
174 | [MLOps In Practice ‚Äì How To Run Your Machine Learning Models In Production At Enterprise Scale](https://youtu.be/LQzTyV5suQo) |  | | WIP | [notes]() 
175 | [Software Engineering Principles](https://youtu.be/yP6Eyny7p20) | All Data Scientists Should Learn Software Engineering Principles // Catherine Nelson // Podcast #245 | | WIP | [notes](notes/2024/general/swe_ds.md) 
176 | [death of fine tuning](https://youtu.be/h1c_jmk97Ss) | Why Fine Tuning is Dead w/Emmanuel Ameisen | | CANCELLED | [notes]() 
177 | [clean code](https://youtu.be/uAzxM-RrKw8) | Clean Code for Data Scientists // Matt Sharp // MLOps Podcast # 160 | | DONE | [notes](notes/2024/general/clean_code.md) 


26 | []() |  | | TODO | [notes]() 


TODO Github

https://github.com/aws-samples/Easy_Fintune_LLM_using_SageMaker_with_LLama_Factory/blob/main/03.deploy_on_SageMaker_endpoint_lmi_vllm.ipynb
https://github.com/arjuntheprogrammer/sagemaker_finetune_mistral7B_and_deploy/blob/main/notebooks/train-deploy-llm.ipynb
https://github.com/huggingface/notebooks/blob/main/sagemaker/24_train_bloom_peft_lora/sagemaker-notebook.ipynb
https://github.com/huggingface/notebooks/blob/main/sagemaker/28_train_llms_with_qlora/sagemaker-notebook.ipynb
https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/Llama2/Llama2-7b/LMI/llama2-7b-multi-lora-adapters-sagemaker.ipynb

https://www.philschmid.de/sagemaker-train-evalaute-llms-2024
https://aws.amazon.com/blogs/machine-learning/model-management-for-lora-fine-tuned-models-using-llama2-and-amazon-sagemaker/


https://github.com/krishnaik06/Generative-AI-With-Cloud/tree/main/AWS%20sagemaker (https://youtu.be/U72q95dHpRo)
https://github.com/aws-samples/Easy_Fintune_LLM_using_SageMaker_with_LLama_Factory
https://github.com/aws-samples/Easy_Fintune_LLM_using_SageMaker_with_LLama_Factory/blob/main/01.llama_factory_finetune_on_SageMaker_QLora-Local-Notebook.ipynb
https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing
https://github.com/DaoyuanLi2816/Llama3-8B_Emotion_Text_Classification_LoRA/tree/master

TODO videos

https://youtu.be/2tm0b8_TVr8

https://youtu.be/BD9TkvEsKwM

https://youtu.be/-1Sx4bYZzCk

https://youtu.be/iy9Z4DyHxvE pyreft

https://youtu.be/hf5N-SlqRmA longlora

https://vinija.ai/nlp/parameter-efficient-fine-tuning

https://superlinked.com/vector-db-comparison



AWS
AIM218: Build your first generative Al application with Amazon Bedrock
DAT505: Build generative-Al-powered search with Amazon Aurora & Amazon RDS
DAT305: Get started with Amazon Neptune, LLMs, and LangChain 
ANT312: Using Amazon OpenSearch Service as a vector database for gen Al apps
AIM340: Customize your FMs securely to deliver differentiated experiences
DAT407: Best practices for querying vector data for gen Al in PostgreSQL

lin vs lch :
https://youtu.be/g84uWgVXVYg
https://youtu.be/xEgUC4bd_qI
https://www.youtube.com/playlist?list=PLuu6A6nYhUZ-uBQEPhklIXww3xLeGnRhD



https://youtu.be/M8FY4ZvAf5w
https://youtu.be/s-jYxgKMqRc
https://www.youtube.com/watch?v=kmkcNVvEz-k


new finetunign
https://huggingface.co/docs/trl/main/en/sft_trainer
https://arxiv.org/abs/2310.05914
https://github.com/unslothai/unsloth
https://arxiv.org/abs/2402.09353
https://arxiv.org/abs/2402.12354
https://arxiv.org/html/2405.12130v1

dora explanation
https://youtu.be/m7KQdGSr0Dg

RAG better chuncking
https://youtu.be/m6P1Rp91AzM

Raptor
https://youtu.be/zfHQSr_s9PM
https://youtu.be/c9EVkLDd6_Q
https://youtu.be/bpeeqbBIH1A
https://youtu.be/37JSz9SvECI
https://youtu.be/jbGchdTL7d0 : https://github.com/langchain-ai/rag-from-scratch/tree/main, https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb

litllm
https://youtu.be/1Dh6NpjiXq4

Memorization
https://youtu.be/_GkHZQYFOGM

DPO
https://youtu.be/E5kzAbD8D0w
https://youtu.be/5K3zzEM2Nnw
https://youtu.be/pzh2oc6shic 
https://youtu.be/HCFTXTn1PHA
https://youtu.be/EKF4ZJrzPDs
https://youtu.be/Sj35vzljugI

PODcast
https://youtu.be/CyprtaOZxu0

Decoder encoder
https://www.youtube.com/watch?v=6ue7W5DhWbs

Trans4mrs
https://www.youtube.com/watch?v=fMGPF2gpK4w

Galore
https://youtu.be/2_6aHjHIcC4


DEJAU
https://youtu.be/DUkWMoi5nG4

RAFT
https://youtu.be/l3F1MFM47v8
https://youtu.be/sqPckknlgDc
https://www.youtube.com/watch?v=hH3k9KWmzfA
https://youtu.be/pira_p6aRVA

Instruct Tuned
https://www.youtube.com/watch?v=eTieetk2dSw&pp=ygUMaW5zdHJ1Y3QgbGxt

Claude3
https://youtu.be/Evg4HXvsYVY
https://docs.anthropic.com/claude/docs/helper-metaprompt-experimental
https://github.com/anthropics/anthropic-cookbook/

---

Elkevated RAG langchan
https://youtu.be/XXnc55zypU0


Txs turorial
~~https://youtu.be/YIx6IRg3m1E~~

Advaneced retrivalk
https://youtu.be/KQjZ68mToWo
https://youtu.be/rTSxt8DY8BE
https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6
https://medium.com/@bijit211987/optimizing-rag-for-llms-apps-53f6056d8118



https://github.com/eugeneyan/open-llms
https://klu.ai/blog/open-source-llm-models
https://www.datacamp.com/blog/top-open-source-llms

## Jargons
- models :
    - Mistral, Falcon, Bloom, T5, Claude 3, Gemini, Gemma, plam2, phi, dbrx, llama, openai, babyllm, Mosaic MPT
    - Quiet-STaR, rerank3
    - RecurrentGemma(https://arxiv.org/pdf/2402.19427.pdf), jamba 
    - mergekit
    - LM-Cocktail
- ViT:
    - 
    - LVLM-Intrepret
    - controlNet++
- Audio
    - udio
    - suno
- data and tools :
    - ollama, alpaca, LMStudio, metaGPT, perplexity, orca, axolotl , instruct tuned, llm foundry, llamafactory, lightening ai
    - Mixture-of-Depths, 
    - mixture of experts
    - mixture of adpapters : phatgoose
    - safemate
    - SAFE
    - unstructured
- libraries
    - lang
        - chain
            - extract
        - serve
        - smith
        - LCEL
    - llamaindex
        - llamaparser
    - dspy
- Rag techniques
    - LOTR (langchain)
    - graph rag
    - long context reorder
    - Ensemble retriver
    - CRAG
    - multi query retrival
    - Self-RAG
    - MultiQueryRetriever
    - Contextual Compression Ensemble Retrievers
    - Self-Querying Retrievers
    - Time Weighted Vector Store Retrievers
    - Re-Rank, RankGPT, RAG-Fusion 
    - HyDe
    - cohere's Command R+ for RAG in prod
    - llamaindex's AutoVector
    - llama index citation query engine
    - Verba
    - autoRag
    - Hippo rag
- Embedding
    - google palm
    - openai
    - FB's llama 2 
    - HF 
- chunking 
    - raptor, semantic, agentic, doc summary, colbertv2
    - metadata based
    - Semantic splitting
- Context handeling
    - LLoCO
    - Leave no context behind
- Better training
    - RHO-1
- platforms :
    - lavauge, skyvern, cohere
- alignment training :
    - PPO(RLHF), DPO, SDPO, ORPO, KTO, IPO, NAC, DNO, WARP
    - FT, RAG, RAFT
- peft :
    - LONGLORA, LOFTQ, RSLORA, LORA, QLORA, LORA+, GALORE, DORA, NEFT, unsloth, PISSA, QDORA, MORA, ReLora
    - LISA, QALora
    - Pytorch's torchtune
- reft
    - loReft
- ???
    - rope scaling, flash attention 2
- guardrails
    - nemo
    - guardrail.ai
    - llamaguard
    - aws guardrails
    - semantic router
    - colang
    - prompt injection
    - anti jailbreak
- evaluation :
    - Code : human eval
    - ROUGE, unieval, ragas, autoeval
    - Github : swe-bench
    - LM perpexity over long document
    - pass key retirival task
    - and long doc Q&A and summarization
    - ICL
    - lmsys.org
    - Berkley function calling
    - Giskard
    - GPT Eval
    - GPT Score
    - WEAT
    - Vectara
    - weights and bias
    - Pheonix eval
    - DeepEval
    - AutoRAGAS (costly)
    - CICD CircleCI
- Benchmarks
    - arc
    - truthfulqa
    - gsm8k
    - hellaswag
    - mmlu
    - winogrande
    - Open LLM leaderboard
    - MT-bench
    - CHatbot arena
    - AlpacaEval
    - IFEval
    - LangChain Benchmark
- Agent :
    - crew ai, reAct agent, self-refine, AutoGen
    - Inventor, APNL, Language Agent Tree search, LDB+Reflexion, CodeT, MetaGPT, ANPL, AgentCoder
    - devin, [swe-agent](https://github.com/princeton-nlp/SWE-agent),
    - babygpt, autoGPT, gpt-researcher, openGPT
    - toolformer
    - PrasionAI
    - 
- inference :
    - chain of thought
    - vllm
- ???
    - function calling llm
- quantization :
    - gptq, gguf(GGml), awq, exl2, hqq
- agentic :
    - reflection, tool, planning, multi agent collboration
- Vector DB
    - pinecone (cloud)
    - chroma
    - Faiss
    - Vespa
    - Milvus
    - weaviate (cloud)
    - AWS aurora with pgvector postgres
    - AWS Open search
    - Redis
- AWS
    - sagemaker
    - bedrock
    - hyperpod
    - Jumpstart
- ui
    - chainlit
    - gradio
- long context window
    - alabi, rope embedding
    - cope https://arxiv.org/abs/2405.18719
    - context window sliding and segmentation
    - positional extrapolation and interpolation
    - sliding memory window, chunk segmentation
- Hacks
    - Many-shot Jailbreaking
- For edge mobile
    - Octopus v2
    - mediapipe
    - tflite
    - https://fluttergems.dev/chatgpt-llm-genai/
- Smaller models
    - JetMoE

- ALT models
    - mamba
    - jamba, 1.5
    - RWKV 

- Hosting LLMs challenge
    - Inference best practices 
        - Continuous Batching 
        - Paged Attention
        - Flash Attention 
        - Prefix Caching
    - Low-level customizations 
        - Stop condition 
        - Enforce output format
    - vllm, llamac++. openllm, mlc-llm
    - tensorRT-llm
    - Auto-scaling based on traffic
    - Scaling to/from Zero
    - Cold start optimization w/ large container and model files
    - Concurrency based autoscaling
    - Async non-blocking invocation
    - Shared model replica
    - Dynamic Batching

Self-Refine: Iterative Refinement with Self-Feedback, Madaan et al. (2023)
Reflexion: Language Agents with Verbal Reinforcement Learning, Shinn et al., (2023)



https://medium.com/@kariniai/navigating-genaiops-in-enterprises-challenges-and-best-practices-version-1-0-c6f6b2c0d18d

https://towardsdatascience.com/genaiops-evolving-the-mlops-framework-b0012f936379

https://huggingface.co/Telugu-LLM-Labs/Indic-gemma-2b-finetuned-sft-Navarasa-2.0

https://lakefs.io/blog/12-vector-databases-2023/
https://www.datacamp.com/blog/the-top-5-vector-databases
https://byby.dev/vector-databases
https://medium.com/koalabs/vector-databases-a-list-43733545feea
https://www.geeksforgeeks.org/vector-databases-that-you-must-try/
https://github.com/krishnaik06/Roadmap-To-Learn-Generative-AI-In-2024
https://github.com/krishnaik06/Data-Science-Projects-For-Resumes
https://github.com/krishnaik06/Perfect-Roadmap-To-Learn-Data-Science-In-2024
https://sebastianraschka.com/blog/2024/lora-dora.html
https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms
https://arxiv.org/html/2402.10958v1
https://www.kdnuggets.com/7-steps-to-mastering-large-language-model-fine-tuning
https://www.promptingguide.ai/research/rag
https://www.axios.com/2024/03/27/ai-chatbot-letdown-hype-reality
LONG-FORM FACTUALITY IN LARGE LANGUAGE
MODELS
https://www.marktechpost.com/2024/04/08/google-deepmind-and-anthropic-researchers-introduce-equal-info-windows-a-groundbreaking-ai-method-for-efficient-llm-training-on-compressed-text/
https://paperswithcode.com/
https://blog.salesforceairesearch.com/moirai/

https://mltechniques.com/2024/04/12/hallucination-free-self-tuned-fast-hierarchical-llms-with-multi-token-embeddings/
https://www.snowflake.com/blog/introducing-snowflake-arctic-embed-snowflakes-state-of-the-art-text-embedding-family-of-models/
https://www.analyticsvidhya.com/blog/2024/04/googles-transformerfam-a-breakthrough-in-long-context-processing/
https://www.analyticsvidhya.com/blog/2024/04/pytorchs-torchtune-revolutionizing-llm-fine-tuning/
https://towardsdatascience.com/pushing-boundaries-integrating-foundational-models-e-g-556cfb6d0632
https://analyticsindiamag.com/ai-platforms-will-control-what-everybody-sees-says-metas-ai-chief-yann-lecun/
https://www.kdnuggets.com/7-steps-to-mastering-mlops
https://www.kdnuggets.com/7-end-to-end-mlops-platforms-you-must-try-in-2024
https://www.marktechpost.com/2024/04/13/google-ai-introduces-patchscopes-a-machine-learning-approach-that-trains-llms-to-provide-natural-language-explanations-of-their-hidden-representations/
https://www.marktechpost.com/2024/04/11/researchers-at-apple-propose-ferret-ui-a-new-multimodal-large-language-model-mllm-tailored-for-enhanced-understanding-of-mobile-ui-screens/
https://www.marktechpost.com/2024/04/11/researchers-at-apple-propose-ferret-ui-a-new-multimodal-large-language-model-mllm-tailored-for-enhanced-understanding-of-mobile-ui-screens/
https://huggingface.co/papers/2404.12390
https://www.kdnuggets.com/vector-databases-in-ai-and-llm-use-cases
https://towardsdatascience.com/evaluate-anything-you-want-creating-advanced-evaluators-with-llms-e2d540af6090
https://huggingface.co/papers/2404.12253
https://www.marktechpost.com/2024/04/17/google-ai-proposes-transformerfam-a-novel-transformer-architecture-that-leverages-a-feedback-loop-to-enable-the-neural-network-to-attend-to-its-latent-representations/
https://towardsdatascience.com/dont-crash-your-app-load-records-from-the-databse-in-batches-for-better-performance-ab09f3598d96
https://www.marktechpost.com/2024/04/19/this-ai-paper-from-cmu-introduces-agentkit-a-machine-learning-framework-for-building-ai-agents-using-natural-language/?amp
https://magazine.sebastianraschka.com/p/using-and-finetuning-pretrained-transformers
https://venturebeat.com/ai/meta-challenges-transformer-architecture-with-megalodon-llm/
https://www.marktechpost.com/2024/04/17/this-ai-paper-explores-the-fundamental-aspects-of-reinforcement-learning-from-human-feedback-rlhf-aiming-to-clarify-its-mechanisms-and-limitations/
https://towardsdatascience.com/structured-generative-ai-e772123428e4
https://www.liveabout.com/top-free-or-open-source-accounting-programs-14071
https://www.marktechpost.com/2024/04/18/create-tsi-a-generative-ai-rag-toolkit-that-generates-ai-applications-using-llamaindex-with-low-code/
https://www.marktechpost.com/2024/04/19/google-deepmind-releases-penzai-a-jax-library-for-building-editing-and-visualizing-neural-networks/
https://www.bleepingcomputer.com/news/security/github-comments-abused-to-push-malware-via-microsoft-repo-urls/amp/
https://medium.com/decodingml/sota-python-streaming-pipelines-for-fine-tuning-llms-and-rag-in-real-time-82eb07795b87
https://www.searchenginejournal.com/recurrentgemma/514392/
https://timesofindia.indiatimes.com/world/us/artificial-intelligence-has-a-measurement-problem/articleshow/109468730.cms
https://www.philschmid.de/fsdp-qlora-llama3
https://www.answer.ai/posts/2024-04-26-fsdp-qdora-llama3.html
https://www.marktechpost.com/2024/04/19/how-faithful-are-rag-models-this-ai-paper-from-stanford-evaluates-the-faithfulness-of-rag-models-and-the-impact-of-data-accuracy-on-rag-systems-in-llms/
https://bdtechtalks.com/2024/04/22/llm2vec/
https://www.infoworld.com/article/3715323/aws-moves-amazon-bedrock-s-ai-guardrails-and-other-features-to-general-availability.html
https://venturebeat.com/ai/amazon-bedrock-continues-to-lay-down-generative-ai-foundation-for-the-cloud/
https://investors.snowflake.com/news/news-details/2024/Snowflake-Launches-Arctic-The-Most-Open-Enterprise-Grade-Large-Language-Model/default.aspx
https://analyticsindiamag.com/now-run-programs-in-real-time-with-llama-3-on-groq/
https://www.kdnuggets.com/how-to-standout-and-safeguard-your-job-in-the-generative-ai-era
https://www.ndtv.com/business-news/explained-how-big-tech-companies-are-now-expanding-into-indias-smaller-cities-5519685/amp/1
https://www.marktechpost.com/2024/04/22/tencent-ai-lab-developed-alphallm-a-novel-machine-learning-framework-for-self-improving-language-models/?amp
https://www.deccanherald.com/india/eu-found-cancer-causing-chemical-in-527-indian-items-2991515
https://huggingface.co/papers/2404.16811
https://towardsdatascience.com/the-landscape-of-emerging-ai-agent-architectures-for-reasoning-planning-and-tool-calling-a-a95214b743c1
https://towardsdatascience.com/reducing-the-size-of-docker-images-serving-large-language-models-part-2-b7226a0b6514
https://www.analyticsvidhya.com/blog/2024/05/rag-application-with-cohere-command-r-and-rerank/
https://cleanlab.ai/blog/trustworthy-language-model/
https://towardsdatascience.com/relation-extraction-with-llama3-models-f8bc41858b9e
https://www.marktechpost.com/2024/04/26/single-agent-architectures-ssas-and-multi-agent-architectures-maas-achieving-complex-goals-including-enhanced-reasoning-planning-and-tool-execution-capabilities/
https://towardsdatascience.com/moment-a-foundation-model-for-time-series-forecasting-classification-anomaly-detection-1e35f5b6ca76
https://towardsdatascience.com/temperature-scaling-and-beam-search-text-generation-in-llms-for-the-ml-adjacent-21212cc5dddb
https://www.marktechpost.com/2024/04/25/understanding-key-terminologies-in-large-language-model-llm-universe/
https://www.marktechpost.com/2024/04/28/cleanlab-introduces-the-trustworthy-language-model-tlm-that-addresses-the-primary-challenge-to-enterprise-adoption-of-llms-unreliable-outputs-and-hallucinations/
https://www.marktechpost.com/2024/04/28/mistral-rs-a-lightning-fast-llm-inference-platform-with-device-support-quantization-and-open-ai-api-compatible-http-server-and-python-bindings/
https://www.marktechpost.com/2024/04/26/deepmind-researchers-propose-naturalized-execution-tuning-next-a-self-training-machine-learning-method-that-drastically-improves-the-llms-ability-to-reason-about-code-execution/?amp
https://www.kdnuggets.com/7-end-to-end-mlops-platforms-you-must-try-in-2024
https://towardsdatascience.com/can-recommendations-from-llms-be-manipulated-to-enhance-a-products-visibility-64c64fa9cd24
https://www.kdnuggets.com/guide-data-structures-ai-and-machine-learning
https://www.kdnuggets.com/5-mlops-courses-from-google-to-level-up-your-ml-workflow
https://huggingface.co/papers/2404.19737
https://huggingface.co/blog/evaluation-structured-outputs
https://towardsdatascience.com/large-language-model-performance-in-time-series-analysis-4d274b480e24
https://analyticsindiamag.com/pytorch-releases-executorch-alpha-for-deploying-llms-for-edge-devices/
https://www.marktechpost.com/2024/04/25/snowflake-ai-research-team-unveils-arctic-an-open-source-enterprise-grade-large-language-model-llm-with-a-staggering-480b-parameters/
https://www.marktechpost.com/2024/04/30/scrapegraphai-a-web-scraping-python-library-that-uses-llms-to-create-scraping-pipelines-for-websites-documents-and-xml-files/
https://foundationcapital.com/the-future-of-generative-agents/
https://huggingface.co/papers/2405.01535
https://towardsdatascience.com/how-to-use-re-ranking-for-better-llm-rag-retrieval-243f89414266
https://huggingface.co/papers/2405.00332
https://www.marktechpost.com/2024/05/01/free-llm-playgrounds-and-their-comparative-analysis/?amp
https://www.kdnuggets.com/5-simple-steps-to-automate-data-cleaning-with-python
https://www.marktechpost.com/2024/04/27/this-ai-paper-proposes-flora-a-novel-machine-learning-approach-that-leverages-federated-learning-and-parameter-efficient-adapters-to-train-visual-language-models-vlms/
https://abvijaykumar.medium.com/multi-agent-architectures-e09c53c7fe0d
https://www.marktechpost.com/2024/05/02/kolmogorov-arnold-networks-kans-a-new-era-of-interpretability-and-accuracy-in-deep-learning/
https://thenewstack.io/sql-schema-generation-with-large-language-models/
https://www.blackhatethicalhacking.com/tools/pphack/
https://towardsdatascience.com/reducing-the-size-of-docker-images-serving-llm-models-b70ee66e5a76
https://www.marktechpost.com/2024/05/03/a-novel-ai-approach-to-enhance-language-models-multi-token-prediction/?amp
https://towardsdatascience.com/get-underlined-text-from-any-pdf-b7b068ca3d64
https://www.marktechpost.com/2024/05/04/prometheus-2-an-open-source-language-model-that-closely-mirrors-human-and-gpt-4-judgements-in-evaluating-other-language-models/
https://www.marktechpost.com/2024/05/06/nvidia-publishes-a-competitive-llama3-70b-quality-assurance-qa-retrieval-augmented-generation-rag-fine-tune-model/
https://www.marktechpost.com/2024/05/05/deciphering-transformer-language-models-advances-in-interpretability-research/
https://www.analyticsvidhya.com/blog/2024/05/advanced-rag-technique-langchain-react-and-cohere/
https://www.sahivalue.com/products/used-refurbished-google-pixel-4a-128gb-685302/293890000037435112
https://www.analyticsvidhya.com/blog/2024/05/python-tricks-to-make-pandas-faster/
https://towardsdatascience.com/how-does-temperature-impact-next-token-prediction-in-llms-779bd908f2cf
https://www.tweag.io/blog/2024-02-06-evaluating-retrieval-in-RAGs/
https://hackaday.com/2024/05/08/ai-helps-make-web-scraping-faster-and-easier/
https://techxplore.com/news/2024-05-framework-hallucinations-text-generated-llms.amp
https://analyticsindiamag.com/the-world-needs-something-better-than-the-transformer/
https://entrackr.com/2024/05/cybersecurity-startup-treacle-raises-pre-seed-round-led-by-ipv/
https://www.insightpartners.com/ideas/ai-agents-disrupting-automation/
https://towardsdatascience.com/n-beats-the-first-interpretable-deep-learning-model-that-worked-for-time-series-forecasting-06920daadac2
https://www.marktechpost.com/2024/05/10/this-ai-paper-by-microsoft-and-tsinghua-university-introduces-yoco-a-decoder-decoder-architectures-for-language-models/
https://www.marktechpost.com/2024/05/10/anthropic-ai-launches-a-prompt-engineering-tool-that-generates-production-ready-prompts-in-the-anthropic-console/
https://www.marktechpost.com/2024/05/12/knowhalu-a-novel-ai-approach-for-detecting-hallucinations-in-text-generated-by-large-language-models-llms/
https://www.marktechpost.com/2024/05/11/uc-berkeley-researchers-introduce-learnable-latent-codes-as-bridges-lcb-a-novel-ai-approach-that-combines-the-abstract-reasoning-capabilities-of-large-language-models-with-low-level-action-policies/
https://techxplore.com/news/2024-05-framework-hallucinations-text-generated-llms.html
https://www.the420.in/750-applications-cyber-warriors-fcrf-virtual-meetup/
https://searchengineland.com/entity-oriented-search-the-evolution-of-information-retrieval-explained-440395
https://towardsdatascience.com/the-lesser-known-rising-application-of-llms-775834116477
https://www.techtarget.com/searchenterpriseai/tip/How-to-build-an-MLOps-pipeline
https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/
https://towardsdatascience.com/safeguard-your-llm-chatbot-with-llama-guard-2-ff5f5aa0f894
https://www.livemint.com/ai/artificial-intelligence/ai-experts-india-inc-hiring-demand-skills-gaps-11715599729345.html
https://huggingface.co/blog/agents
https://huggingface.co/papers/2405.09220
https://www.marktechpost.com/2024/05/15/decoding-complexity-with-transformers-researchers-from-anthropic-propose-a-novel-mathematical-framework-for-simplifying-transformer-models/
https://www.kdnuggets.com/the-best-strategies-for-fine-tuning-large-language-models
https://builtin.com/artificial-intelligence/artificial-intelligence-cybersecurity
https://www.rungalileo.io/blog/mastering-rag-how-to-select-a-reranking-model
https://www.pinecone.io/learn/series/rag/rerankers/
https://gradientflow.com/the-new-era-of-efficient-llm-deployment/
https://a16z.com/emerging-architectures-for-llm-applications/


## Channels : 
1. Freecodecamp
2. Mircosoft reactor
3. AWS
4. AI Anytime
5. Shaw Talebi
6. Sam Witteveen
7. Venelin Valkov
8. PyTorch
9. Prompt Engineering
10. LlamaIndex
11. Pradip Nichite
12. James Briggs
13. Alex Chao
14. DVCorg
15. Adrian Twarog
16. Rabbit Holke Syndrome
17. Zilliz
18. AI Makerspace
19. Johnny Code
20. Tim Carambat
21. DSwithBappy
22. Greg Kamradt
23. AI with Tarun
24. CMU DB group
25. Ryan nolan Data
26. Thursday Content
27. AI Round table
28. Sunny Savita
29. Brian H Hough
30. AWS Event
31. MLOPs Community
32. DeepLearningAI
33. Daniel Bourke
34. Harvard Data Science Initiative
35. KGP Talkie
36. Jonathan Yarkoni
37. Umar Jamil
38. Coding Tech
39. Andrej Karpathy
40. Keith Galli
41. Entry Point AI
42. Trelis Research
43. What's AI by Louis-Fran√ßois Bouchard
44. Coding Crashcourse
45. Oxen
46. brev
47. sentdex
48. Gabriel Mongaras
49. TwoSetAI
50. Super Data Science ML
51. Matt Wolfe
52. PyData
53. Yannic Kilcher
54. Stanford Online
55. Matthew Berman
56. AI paper Academy
57. 1littlecoder
58. AI engineer
59. Code Emporium
60. Arxiv Papers
61. AI Coffee Break with Letitia
62. LLMops space
63. Pieter Abbeel
64. AI Tools Search
65. Greg Kamradt
66. Mervin Praison
67. AI FLux
68. Deci AI
69. HuggingFace

1. Maxime Labonne


# Libraries
- AutoModelForCausalLM
- AutoTokenizer
- BitsAndBytesConfig
- HfArgumentParser
- TrainingArguments
- pipeline
- logging
- RecursiveCharacterTextSplitter
- PyPDFDirectoryLoader
- PromptTemplate
- RetrievalQA
- PDFReader
- RAGPretrainedModel
- dspy
- ChatPromptTemplate
- StrOutputParser
- ChatOpenAI
- DirectoryLoader
- LoraConfig
- PeftModel
- get_peft_model
- prepare_model_for_kbit_training
- DPOTrainer
- SFTTrainer
- axolotl
- hugging face
- accelerate
- CTransformers
- faiss-cpu
- tiktoken
- OpenAIEmbeddings
- Pinecone
- ConversationBufferMemory
- SequentialChain
- sentence_transformers
- bfloat16
- SubDocSummaryPack
- from unsloth import FastLlamaModel
- xformers. it's a package that provides libraries an utilities to facilitate the work with transformers models. We
need to install in order to avoid an error when we work with the model and embeddings.
- SentenceTransformer
- faiss

# Advanced
Policy Gradients and Advantage Estimation : https://youtu.be/AKbX1Zvo7r8
sDPO : https://youtu.be/O77abFFxk_Q