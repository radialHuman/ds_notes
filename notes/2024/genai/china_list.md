### 0. Text classification
https://github.com/search?q=ernie+text+classification&type=repositories&s=stars&o=desc
https://github.com/labteral/ernie
https://github.com/lonePatient/ERNIE-text-classification-pytorch/tree/master
https://towardsdatascience.com/https-medium-com-gaganmanku96-fine-tune-ernie-2-0-for-text-classification-6f32bee9bf3c
https://www.activestate.com/blog/bert-vs-ernie-the-natural-language-processing-revolution/

### 1. [Install Chinese Tiny LLM Locally - Chinese-First AI Model](https://youtu.be/Ayi15gOlcHc)
- https://huggingface.co/m-a-p/CT-LLM-SFT-DPO
- MiniCPM-2B-sft (min, 2024) 
- Bloom-1.7B (Le Scao et al., 2022)
- Stablelm-zephyr-3B (Tunstall et al., 2023) 
- TinyLlama-1.1B-Chat-v1.0 (Zhang et al., 2024)
- Gemma-2b-it (Team et al., 2024) 
- Qwen1.5-1.8B-Chat (Bai et al., 2023)
- 4.5gb

### 2. [China's Qwen VL wins Big Time!!!](https://youtu.be/ElrSJDg23Po)
- https://huggingface.co/Qwen/Qwen-VL
- vision model by Alibaba
- text image and bounded box
- chat verison is also vaialable
    - gradio link for chat
- has a qunatized version


### 3. [Chinese LLMs List](https://youtu.be/9AoBjLwdiwU)
- qwen 7b : free for small use, org with more than 100m needs license
- Baichuan-13B : suko tencent, free for academic, needs license for corporates
- AquilaChat-7B, AquilaChat-33B, AquilaCode, Wu Dao Vision : by bejing ai academy

### 4. [Install Yi 34B Locally - Chinese English Bilingual LLM](https://youtu.be/CVQvj4Wrh4w)
- https://huggingface.co/01-ai/Yi-34B
- has a quantized verison
- by 01AI
- Yi means 1
- 6b verison is avaialable also
- 32k inference lenght
- used bechmarking tech like hellaswag, obqa, csqa etc in llama 2
- bilingual, chinese and english

### 5. [BVTV: China’s AI capabilities | REUTERS](https://youtu.be/kW0rHCuTYE4)
- Ernie by Baidu


### 6. [Chinese AI Giant iFlyTek Trains LLMs on Huawei's Platform](https://youtu.be/4ylP-vyau9c)
- Xinghuo 4

### Video
Kling

### 7. [Chinese LLMs Tracker](https://chinaobservers.eu/chinese-llms-tracker/)
- Yi : O1AI
- Shi Shuo : 4Paradigm
- Nanbei Pavilion : BOSS Zhipin
- Magic Cube : CreateView Edu-Tech
- Yiye Qingzhou : Effyic
- Yue Al : iReader Technology Co., Ltd.
- New Intelligent Q&A : Maimai
- Al Q&A Robot : SMZDM ("What's Worth Buying") run by Beijing Zhidemai Technology
- XGPT : ThreatBook
- Moxiaoxian : Xianyuan Technology/ Frontis Al


### 8. [Recent Trends in China’s Large Language Model Landscap](https://cdn.governance.ai/Trends_in_Chinas_LLMs.pdf)
- PanGu-α (207B parameters) and Yuan 1.0 (245B parameters)
- Beijing Academy of Artificial Intelligence (BAAI) also released one of the world’s largest mixture-ofexpert (MoE) models called BaGuaLu (14.5T parameters).
- DeepMind’s Chinchilla model
- Baidu’s ERNIE 3.0
- WuDao 1.0’s English-language WenHui (GLM) model 
- MSRA and Peking University’s multimodal NÜWA
- CLUE (Chinese Language Understanding Evaluation) and CUGE (Chinese Language Understanding and Generation Evaluation) benchmarks
#### Models
- WuDaoWen Yuan 1.0 (CPM)¹³ 12/1/2020 BAAI, Tsinghua University
- M6¹⁴ 3/1/2021 Tsinghua University, Alibaba 100B (Mixture of Experts, MoE)
- WuDaoWenLan 1.0¹⁵ 3/11/2021 Renmin University of China, Chinese Academy of Sciences
- WuDaoWen Hui 1.0 (GLM)⁹ 3/18/2021 Tsinghua University,BAAI, MIT, Shanghai Qi Zhi Institute
- PLUG¹⁶ 4/19/2021 Alibaba
- PanGu-α¹⁷ 4/26/2021 Huawei, Recurrent AI, Peking University, and Peng Cheng Lab
- ConSERT¹⁸ 5/25/2021 Beijing University of Posts and Telecommunications, Meituan
- CogView¹² 5/26/2021 Tsinghua University, Alibaba, BAAI
- M6-T¹⁹ 5/31/2021 Alibaba 
- WuDaoWen Yuan 2.0 (CPM-2)²⁰ 6/24/2021 Tsinghua University, BAAI
- ERNIE 3.0⁸ 7/15/2021 Baidu
- PLATO-XL²¹ 9/20/2021 Baidu
- Zidong Taichu²² 9/27/2021 Chinese Academy of Sciences
- M6-10T²³ 10/8/2021 Alibaba
- Yuan 1.0²⁴ 10/10/2021 Inspur 
- WuDaoWenLan 2.0²⁵ 10/27/2021 Renmin University of China
- NÜWA¹⁰ 11/24/2021 Microsoft Research Asia, Peking University
- ERNIE 3.0 Titan²⁶ 12/23/2021 Baidu, Peng Cheng Lab 
- ERNIEViLG¹¹ 12/31/2021 Baidu 
- BaGuaLu²⁷ 4/2/2022 Tsinghua University, BAAI, Alibaba,
- GLM-130B²⁹ 8/4/2022 Tsinghua University, BAAI, Zhipu.AI 
- CogVideo²⁸ 5/29/2022 Tsinghua University, BAAI
- Taiyi-Stable Diffusion³⁰ 10/31/2022 IDEA CCNL 1
- AltDiffusion ³¹ 11/12/2022 BAAI
- AR-LDM³² 11/20/2022 University of Waterloo, Alibaba, Vector Institute
- ALM 1.0³³ 11/28/2022 BAAI
- MiniCPM3-4B 09/05/2024 Open Lab for Big Model Base by  ModelBest Inc and TsinghuaNLP 
#### Data
- BAAI team released WuDaoCorpora, a bilingual dataset with 2.3TB of cleaned Chinese data and 300GB of cleaned English data from encyclopedias, novels, news, and scientific literature
- multimodal models, the M6 developers from Tsinghua University and Alibaba released the M6-Corpus, the first large-scale multimodal dataset in Chinese
#### Makers
- Beijing Academy of Artificial Intelligence
- Zhejiang Lab
- Peng Cheng Lab
- 

### 9. [China Opens Up AI: Top 5 Large Language Models to Know Now](https://www.turingpost.com/p/llms-in-china)
- 


### 10. [](https://analyticsindiamag.com/beware-of-chinese-open-source-llms/)
- Abacus.ai ready to host the models on their platforms.
- https://huggingface.co/TigerResearch/tigerbot-70b-chat-v2
- Tiger Research, a company that “believes in open innovations”, is a research lab in China under Tigerobo


### 11. [Chinese LLM Developers Explore Domestic Chips Options](https://chinaobservers.eu/chinese-llm-developers-explore-domestic-chips-options/)
- genai regualtion in China https://www.tc260.org.cn/upload/2024-03-01/1709282398070082466.pdf
- LLM DB : https://36kr.com/p/2621227318139272
- biggest players in China’s technological market – Baidu, Tencent, Alibaba, Huawei, iFlytek, SenseTime, and ByteDance. Besides these companies, Chinese research institutions, namely the Chinese Academy of Sciences and Shanghai Artificial Intelligence Laboratory, received approvals for their models


### 12. [Do you follow Chinese LLM development?](https://www.reddit.com/r/LocalLLaMA/comments/17ka7lx/do_you_follow_chinese_llm_development/?rdt=52796)
- https://rank.opencompass.org.cn/leaderboard-llm-v2
- https://cevalbenchmark.com/static/leaderboard.html : eval of models
- https://modelscope.cn/home : huggingface alternative
- https://huggingface.co/Duxiaoman-DI/XuanYuan-70B
- 34B AquilaChat
- chatglm3-6b 
- https://www.zhihu.com/people/wang-jia-hao-53-3/posts : cant access
- https://github.com/datawhalechina
- https://zhuanlan.zhihu.com/p/162057668
- https://github.com/InternLM/
- https://huggingface.co/THUDM
- https://github.com/SkyworkAI/Skywork

### 13. [Why developing countries should look to China to leapfrog into LLM markets](https://www.weforum.org/agenda/2024/06/why-emerging-markets-should-be-part-of-the-commercialization-of-llm-models/)
- ByteDance : Doubao-pro-32k
- Tencent : Hunyuan Standard

### 14. [SenseTime Launches SenseNova 5.0 with Major Upgrades and Industry-Leading Cloud-to-Edge AI Solutions](https://www.youtube.com/watch?v=Xa-LXaXo0T8)
- knowledge
- resoning
- execution
- creative, linguistic, scintific
- multimodal, 10tb token training data synthetic
- 200k inference window
- math and code
- TTI and image parsing
- TTV


### 15. https://stcsm.sh.gov.cn/english/News/20230727/61b69488e2144fef8d6805e692b53292.html
### 16. [Needlebench shaghai ai](https://analyticsindiamag.com/ai-news-updates/shanghai-ai-laboratory-unveils-needlebench-a-new-framework-to-test-long-context-capabilities-of-large-language-models/)

### Github
- https://github.com/wgwang/awesome-LLMs-In-China
- https://github.com/MiuLab/Taiwan-LLM
- https://github.com/ymcui/Chinese-LLaMA-Alpaca
- https://github.com/CVI-SZU/Linly
- https://github.com/ydli-ai/CSL
- https://github.com/yangjianxin1/Firefly
- https://github.com/Facico/Chinese-Vicuna
- https://github.com/LC1332/Chinese-alpaca-lora
- https://github.com/BAAI-Zlab/COIG
- 

### Eval
- cMedKnowQA
- TCMD
- CRiskEval
- PediatricsGPT
- Bench
- FoundaBench
- MLaKE
- LHMKE
- CLongEval
- GAOKAO-MM
- CMNER
- CIF-Bench
- EmoBench
- UHGEval
- TencentLLMEval
- DialogBench

### Papers
- [NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?](https://arxiv.org/pdf/2407.11963)
- [CMMaTH: A Chinese Multi-modal Math Skill Evaluation Benchmark for Foundation Models](https://arxiv.org/abs/2407.12023)
- [MedBench: A Comprehensive, Standardized, and Reliable Benchmarking System for Evaluating Chinese Medical Large Language Models](https://arxiv.org/abs/2407.10990)
- [How Chinese are Chinese Language Models? The Puzzling Lack of Language Policy in China's LLMs](https://arxiv.org/abs/2407.09652)
- [System Report for CCL24-Eval Task 7: Multi-Error Modeling and Fluency-Targeted Pre-training for Chinese Essay Evaluation](https://arxiv.org/abs/2407.08206)
- [DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task](https://arxiv.org/abs/2304.01097)
- [Tuning LLaMA Model with Chinese Medical Knowledge](https://arxiv.org/pdf/2304.06975)
- [Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses](https://arxiv.org/abs/2303.15587)
- [OpenEval: Benchmarking Chinese LLMs across Capability, Alignment and Safety](https://arxiv.org/html/2403.12316v1)
- [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](https://arxiv.org/abs/2404.04167)
---
- [Can Pre-trained Language Models Understand Chinese Humor?](https://arxiv.org/pdf/2407.04105)
- [TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models](https://arxiv.org/pdf/2407.03937)
- [Pinyin Regularization in Error Correction for Chinese Speech Recognition with Large Language Models](https://arxiv.org/abs/2407.01909)
- [CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding Evaluation](https://arxiv.org/abs/2407.01081)
- [Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese](https://arxiv.org/abs/2407.01080)
- [HRDE: Retrieval-Augmented Large Language Models for Chinese Health Rumor Detection and Explainability](https://arxiv.org/abs/2407.00668)
- [YuLan: An Open-source Large Language Model](https://arxiv.org/abs/2406.19853)
- [Methodology of Adapting Large English Language Models for Specific Cultural Contexts](https://arxiv.org/abs/2406.18192)
- [LLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace Them](https://arxiv.org/abs/2406.18034)
- [Retrieval Augmented Instruction Tuning for Open NER with Large Language Models](https://arxiv.org/abs/2406.17305)
- [C-LLM: Learn to Check Chinese Spelling Errors Character by Character](https://arxiv.org/abs/2406.16536)
- [Enhancing Cross-Document Event Coreference Resolution by Discourse Structure and Semantic Information](https://arxiv.org/abs/2406.15990)
- [STARD: A Chinese Statute Retrieval Dataset with Real Queries Issued by Non-professionals](https://arxiv.org/abs/2406.15313)
- [medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs](https://arxiv.org/abs/2406.14326)
- [FoRAG: Factuality-optimized Retrieval Augmented Generation for Web-enhanced Long-form Question Answering](https://arxiv.org/abs/2406.13779)
- [Evaluating the Generalization Ability of Quantized LLMs: Benchmark, Analysis, and Toolbox](https://arxiv.org/abs/2406.12928)
- [ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](https://arxiv.org/abs/2406.12793)
- [Chumor 1.0: A Truly Funny and Challenging Chinese Humor Understanding Dataset from Ruo Zhi Ba](https://arxiv.org/abs/2406.12754)
- [Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models](https://arxiv.org/abs/2406.12182)
- [Are Large Language Models True Healthcare Jacks-of-All-Trades? Benchmarking Across Health Professions Beyond Physician Exams](https://arxiv.org/abs/2406.11328)
- [CHiSafetyBench: A Chinese Hierarchical Safety Benchmark for Large Language Models](https://arxiv.org/abs/2406.10311)
- [GEB-1.3B: Open Lightweight Large Language Model](https://arxiv.org/abs/2406.09900)
- [AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models](https://arxiv.org/abs/2406.09295)
- [DomainRAG: A Chinese Benchmark for Evaluating Domain-specific Retrieval-Augmented Generation](https://arxiv.org/abs/2406.05654)
- [TCMD: A Traditional Chinese Medicine QA Dataset for Evaluating Large Language Models](https://arxiv.org/abs/2406.04941)
- [CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models](https://arxiv.org/abs/2406.04752)
- [UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models](https://arxiv.org/abs/2406.02110)
- [Bi-DCSpell: A Bi-directional Detector-Corrector Interactive Framework for Chinese Spelling Check](https://arxiv.org/abs/2406.01879)
- [PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications](https://arxiv.org/abs/2405.19266)
- [Bench: A Comprehensive Classical Chinese Understanding Benchmark for Large Language Models](https://arxiv.org/abs/2405.17732)
- [FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models](https://arxiv.org/abs/2404.18359)
- [CRE-LLM: A Domain-Specific Chinese Relation Extraction Framework with Fine-tuned Large Language Model](https://arxiv.org/abs/2404.18085)
- [MLaKE: Multilingual Knowledge Editing Benchmark for Large Language Models](https://arxiv.org/abs/2404.04990)
- [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](https://arxiv.org/abs/2404.04167)
- [Measuring Taiwanese Mandarin Language Understanding](https://arxiv.org/abs/2403.20180)
- [Attention-aware semantic relevance predicting Chinese sentence reading](https://arxiv.org/abs/2403.18542)
- [Chinese Offensive Language Detection:Current Status and Future Directions](https://arxiv.org/abs/2403.18314)
- [Exploring the Privacy Protection Capabilities of Chinese Large Language Models](https://arxiv.org/abs/2403.18205)
- [COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning](https://arxiv.org/abs/2403.18058)
- [LM-Combiner: A Contextual Rewriting Model for Chinese Grammatical Error Correction](https://arxiv.org/abs/2403.17413)
- [Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations](https://arxiv.org/abs/2403.14112)
- [Hyacinth6B: A large language model for Traditional Chinese](https://arxiv.org/abs/2403.13334)
- [LHMKE: A Large-scale Holistic Multi-subject Knowledge Evaluation Benchmark for Chinese Large Language Models](https://arxiv.org/abs/2403.12601)
- [OpenEval: Benchmarking Chinese LLMs across Capability, Alignment and Safety](https://arxiv.org/abs/2403.12316)
- [MCFEND: A Multi-source Benchmark Dataset for Chinese Fake News Detection](https://arxiv.org/abs/2403.09092)
- [Yi: Open Foundation Models by 01.AI](https://arxiv.org/abs/2403.04652)
- [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](https://arxiv.org/abs/2403.03514)
- [Breeze-7B Technical Report](https://arxiv.org/abs/2403.02712)
- [An Improved Traditional Chinese Evaluation Suite for Foundation Model](https://arxiv.org/abs/2403.01858)
- [Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral](https://arxiv.org/abs/2403.01851)
- [MulCogBench: A Multi-modal Cognitive Benchmark Dataset for Evaluating Chinese and English Computational Language Models](https://arxiv.org/abs/2403.01116)
- [Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark](https://arxiv.org/abs/2402.19248)
- [GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation](https://arxiv.org/abs/2402.15745)
- [RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning](https://arxiv.org/abs/2402.14840)
- [Small Language Model Is a Good Guide for Large Language Model in Chinese Entity Relation Extraction](https://arxiv.org/abs/2402.14373)
- [CMNER: A Chinese Multimodal NER Dataset based on Social Media](https://arxiv.org/abs/2402.13693)
- [CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models](https://arxiv.org/abs/2402.13109)
- [CFEVER: A Chinese Fact Extraction and VERification Dataset](https://arxiv.org/abs/2402.13025)
- [A Chinese Dataset for Evaluating the Safeguards in Large Language Models](https://arxiv.org/abs/2402.12193)
- [EmoBench: Evaluating the Emotional Intelligence of Large Language Models](https://arxiv.org/abs/2402.12071)
- [AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical Interaction Simulator](https://arxiv.org/abs/2402.09742)
- [An Empirical Study on Large Language Models in Accuracy and Robustness under Chinese Industrial Scenarios](https://arxiv.org/abs/2402.01723)
- [CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2401.17043)
- [CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning](https://arxiv.org/abs/2401.14011)
- [CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark](https://arxiv.org/abs/2401.11944)
- [Using Large Language Model for End-to-End Chinese ASR and NER](https://arxiv.org/abs/2401.11382)

- [ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain](https://arxiv.org/abs/2401.04898)
- [TechGPT-2.0: A large language model project to solve the task of knowledge graph construction](https://arxiv.org/abs/2401.04507)
- [MERBench: A Unified Evaluation Benchmark for Multimodal Emotion Recognition](https://arxiv.org/abs/2401.03429)
- [Text2MDT: Extracting Medical Decision Trees from Medical Texts](https://arxiv.org/abs/2401.02034)
- [ShennongAlpha: an AI-driven sharing and collaboration platform for intelligent curation, acquisition, and translation of ](https://arxiv.org/abs/2401.00020)natural medicinal material knowledge
- [Unified Lattice Graph Fusion for Chinese Named Entity Recognition](https://arxiv.org/abs/2312.16917)
- [HyKGE: A Hypothesis Knowledge Graph Enhanced Framework for Accurate and Reliable Medical LLMs Responses](https://arxiv.org/abs/2312.15883)
- [YAYI 2: Multilingual Open-Source Large Language Models](https://arxiv.org/abs/2312.14862)
- [Aurora:Activating Chinese chat capability for Mixtral-8x7B sparse Mixture-of-Experts through Instruction-Tuning](https://arxiv.org/abs/2312.14557)
- [MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models](https://arxiv.org/abs/2312.12806)
- [TigerBot: An Open Multilingual Multitask LLM](https://arxiv.org/abs/2312.08688)
- [Analyzing the Inherent Response Tendency of LLMs: Real-World Instructions-Driven Jailbreak](https://arxiv.org/abs/2312.04127)
- [AlignBench: Benchmarking Chinese Alignment of Large Language Models](https://arxiv.org/abs/2311.18743)
- [Taiwan LLM: Bridging the Linguistic Divide with a Culturally Aligned Language Model](https://arxiv.org/abs/2311.17487)
- [UHGEval: Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation](https://arxiv.org/abs/2311.15296)
- [CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue Generation](https://arxiv.org/abs/2311.14539)
- [Flames: Benchmarking Value Alignment of LLMs in Chinese](https://arxiv.org/abs/2311.06899)
- [ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences](https://arxiv.org/abs/2311.06025)
- [TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for Human-Aligned LLMs](https://arxiv.org/abs/2311.05374)
- [FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization](https://arxiv.org/abs/2311.02271)
- [DialogBench: Evaluating LLMs as Human-like Dialogue Systems](https://arxiv.org/abs/2311.01677)
- [ChineseWebText: Large-scale High-quality Chinese Web Text Extracted with Effective Evaluation Model](https://arxiv.org/abs/2311.01149)
- [JADE: A Linguistics-based Safety Evaluation Platform for Large Language Models](https://arxiv.org/abs/2311.00286)
- [Continuous Training and Fine-tuning for Domain-Specific Language Models in Medical Question Answering](https://arxiv.org/abs/2311.00204)
- [TLM: Token-Level Masking for Transformers ](https://arxiv.org/abs/2310.18738)
- [Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare](https://arxiv.org/abs/2310.17956)
- [PromptCBLUE: A Chinese Prompt Tuning Benchmark for the Medical Domain](https://arxiv.org/abs/2310.14151)
- [Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model](https://arxiv.org/abs/2310.09089)
- [Evaluating Hallucinations in Chinese Large Language Models](https://arxiv.org/abs/2310.03368)
- [MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models](https://arxiv.org/abs/2309.13079)
- [Goal-Oriented Prompt Attack and Safety Evaluation for LLMs](https://arxiv.org/abs/2309.11830)
- [C-Pack: Packaged Resources To Advance General Chinese Embedding](https://arxiv.org/abs/2309.07597)
- [SafetyBench: Evaluating the Safety of Large Language Models](https://arxiv.org/abs/2309.07045)
- [MedChatZH: a Better Medical Adviser Learns from Better Instructions](https://arxiv.org/abs/2309.01114)
- [A Small and Fast BERT for Chinese Medical Punctuation Restoration](https://arxiv.org/abs/2308.12568)
- [CMB: A Comprehensive Medical Benchmark in Chinese](https://arxiv.org/abs/2308.08833)
- [RSpell: Retrieval-augmented Framework for Domain Adaptive Chinese Spelling Check](https://arxiv.org/abs/2308.08176)
- [Evaluating the Generation Capabilities of Large Chinese Language Models](https://arxiv.org/abs/2308.04823)
- [CLEVA: Chinese Language Models EVAluation Platform](https://arxiv.org/abs/2308.04813)
- [Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue](https://arxiv.org/abs/2308.03549)
- [JIANG: Chinese Open Foundation Language Model](https://arxiv.org/abs/2308.00624)
- [SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark ](https://arxiv.org/abs/2307.15020)
- [ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination](https://arxiv.org/abs/2305.12945)
- [Huatuo-26M, a Large-scale Chinese Medical QA Dataset](https://arxiv.org/abs/2305.01526)
- [HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge](https://arxiv.org/abs/2304.06975)
- [DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task](https://arxiv.org/abs/2304.01097)
- [MCSCSet: A Specialist-annotated Dataset for Medical-domain Chinese Spelling Correction](https://arxiv.org/abs/2210.11720)
- [End-to-end Clinical Event Extraction from Chinese Electronic Health Record](https://arxiv.org/abs/2208.09354)
- [CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark](https://arxiv.org/abs/2106.08087)
- [Fine-tuning ERNIE for chest abnormal imaging signs extraction](https://arxiv.org/abs/2010.13040)
- [Applications of BERT Based Sequence Tagging Models on Chinese Medical Text Attributes Extraction](https://arxiv.org/abs/2008.09740)
- [MedDialog: Two Large-scale Medical Dialogue Datasets](https://arxiv.org/abs/2004.03329)
- [Fine-tuning BERT for Joint Entity and Relation Extraction in Chinese Medical Text ](https://arxiv.org/abs/1908.07721)


### other
- https://github.com/Hannibal046/Awesome-LLM
- https://github.com/eugeneyan/open-llms
- https://www.economist.com/business/2024/06/13/a-price-war-breaks-out-among-chinas-ai-model-builders