## [Deep Dive into LLMs like ChatGPT](https://youtu.be/7xTGNNLPyMI)
Release date :  Feb 5, 2025
### Idea #LLM 
- 

### Details
#### 00:00:00
- Stage 1 : pre-trianing
    - downlaod and preprocess the inetrnet
    - https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1
    - large quantity of diverse document for training or understanding language working
    - url filtering -> text extraction -> language filtering -> gopher filtering -> minhash dedup -> c4 filter -> custom filter -> PII removal
    - 44tb was used in this blog post 
    - data from commonCrawl : scrapes internet
    - filter by not taking information from these websites
        - https://dsi.ut-capitole.fr/blacklists/
    - language filtering was done by fastext classificaiton
    - the ned result is in https://huggingface.co/datasets/HuggingFaceFW/fineweb
    -  for training a lot od data is taken and concatenated
    - but this cant be directly fed so its encoded usig utf8
    - this is binary
        - it has 0 and 1 but long sequence
    - we need many symbols and shorted sentence
    - better way will be to convert them into bytes so that its numbers and total representation is shorter
        - these symbols are uqniue ids
- BytePair Encoding algorithm is better , sentencePiece too
        - symbols that often go together gets represented by a new symbol
        - this is repeated
        - a vocabulary of 100,000 such symbols is a good start
    - This process is called tokenization
    - Tiktokenizer : cl100k_base is used for gpt base tokeninzation
        - it is case, space sensitive
- Pre-training NN
    - a random lenght of tokens is taken as input and the output as the next token
    - it is trained to predict it
    - the output of this NN is probabiltiy for each token in the vocabulary 100k and its probability
    - the NN is randomly initialized and by back propagation it elarns the working of laguage 
    - this is done for all the text divided in batches on a constant window size
    - this window is the context lenght of the llm
    - this NN is the transformer model
- Inference stage
    - where new data is geenrated by the model
    - first a token is given to the input, it finds out the most proabale token next and geenrates it
    - then the newly generated token is appended to the initial token and now both go as input
    - this goes on 
    - this is schocastic and like flipping coin. its a remixed version of the data it was trained on. so the output is not fixed across time
- How to make gpt2 : https://github.com/karpathy/llm.c/discussions/677
- This si the base model which dreams internet
    - gpt2 by open ai shows the list of things the model does
    - src/model.py : steps while processing
        default_hparams
        shape_list
        softmax
        gelu
        norm
        split_states
        merge_states
        conv1d
        attention_mask
        attn
            split_heads
            merge_heads
            mask_attn_weights
            multihead_attn
        mlp
        block
        past_shape
        expand_tile
        positions_for
    - parameters setting is also required :  which is values of all the parameters
    - base models can be interacted  using ttps://app.hyperbolic.xyz/
    - it just tries to recollect by comrpessing internet in a lossy way, depending on what was said frequently
    - it cant be relied on, also it doesn know whats not in the trinaing dataset
    - though using promtoing we can make base act like a proper assistant but thats also not stable

#### 1:00:00
- Post training
    - needs a conversaytionl dataset with things like how to respond, the tone and what not to tell
    - this dataset is created manually in some cases : human lableers
    - the trianing time in post is a fraction of pree
    - Steps:
        - tokenizaiton fo conversation
        - the conversation eneds to be ina certain format lik e :  https://tiktokenizer.vercel.app/
        - it adds spl token to format them, different for different models
        - now the same way as previouly done, prediciton starts and it trains to get ebtter and close ot the trianing conversation dataset
- to make it better it must go through "Instruct" where it learns hwo to talk using feedback and reinforecement
- Paper for INstructGPT, has techniques on how to train
- dataset from opensource also can be sued to instrcut tune  https://huggingface.co/datasets/OpenAssistant/oasst1
- no more human chat it can be syntheically generated : https://github.com/thunlp/UltraChat
- 
### 2:05:00
- RLHF 
    - socre base don correctness and explanation
    - scored by human in openai
    - might need reward model
- RL
    - newly done by DeepSeek
    - not standardized
    - try different ways of answer
    - evaluate, rephase, reframe and backtracks
    - this is don by lot of tokens, thinking
    - this cot increaes accuracy
[lmarena](https://lmarena.ai/) 
https://buttondown.com/ainews

### Resource
https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1
https://huggingface.co/datasets/HuggingFaceFW/fineweb

ChatGPT https://chatgpt.com/
FineWeb (pretraining dataset): https://huggingface.co/spaces/Hugging...
Tiktokenizer: https://tiktokenizer.vercel.app/
Transformer Neural Net 3D visualizer: https://bbycroft.net/llm
llm.c Let's Reproduce GPT-2 https://github.com/karpathy/llm.c/dis...
Llama 3 paper from Meta: https://arxiv.org/abs/2407.21783
Hyperbolic, for inference of base model: https://app.hyperbolic.xyz/
InstructGPT paper on SFT: https://arxiv.org/abs/2203.02155
HuggingFace inference playground: https://huggingface.co/spaces/hugging...
DeepSeek-R1 paper: https://arxiv.org/abs/2501.12948
TogetherAI Playground for open model inference: https://api.together.xyz/playground
AlphaGo paper (PDF): https://discovery.ucl.ac.uk/id/eprint...
AlphaGo Move 37 video:    â€¢ Lee Sedol vs AlphaGo  Move 37 reactio...  
LM Arena for model rankings: https://lmarena.ai/
AI News Newsletter: https://buttondown.com/ainews
LMStudio for local inference https://lmstudio.ai/

The visualization UI I was using in the video: https://excalidraw.com/


### misc
00:00:00 introduction
00:01:00 pretraining data (internet)
00:07:47 tokenization
00:14:27 neural network I/O
00:20:11 neural network internals
00:26:01 inference
00:31:09 GPT-2: training and inference
00:42:52 Llama 3.1 base model inference
00:59:23 pretraining to post-training
01:01:06 post-training data (conversations)
01:20:32 hallucinations, tool use, knowledge/working memory
01:41:46 knowledge of self
01:46:56 models need tokens to think
02:01:11 tokenization revisited: models struggle with spelling
02:04:53 jagged intelligence
02:07:28 supervised finetuning to reinforcement learning
02:14:42 reinforcement learning
02:27:47 DeepSeek-R1
02:42:07 AlphaGo
02:48:26 reinforcement learning from human feedback (RLHF)
03:09:39 preview of things to come
03:15:15 keeping track of LLMs
03:18:34 where to find LLMs
03:21:46 grand summary
---

