## [RAG 2.0 and The New Era of RAG Agents | Douwe Kiela, CEO at Contextual AI | Inventor of RAG](https://www.youtube.com/watch?v=epAUEgF8OfQ)
Release date : Jun 9, 2025 #rag
### Idea
- The old rag was vdb and llm working but the new one is much more than that 
- it trains on the data distribution using SOTA composnents that work well together

### Details
- useful for usecases with high stakes and low tolerance for mistake
- ROI is when u use it to answer expert and specialist with high reliability
- During inference rag 2.0 behaves like a normal rag but its the training that adds to the old setup
- Main coponents: agents and datastores
- The agent is pointed to where the data lies and then in 10 secs it starts answering with high precision using a platform
- It uses specialised components independently avilable
    - like grounded LM only for RAG
    - SOTA reranker to follow instructions
    - retrival pipeline 
    - eval :  is to start with but the actual eval is based on
    - UAT : user accetability testing, do people find the answer useful
    - natural language unit testing :  to measure the characteristics of a good answer
        - like rules that the answer needs to follow
        - so rules based llm as a judge
        - for regulated industries
- spend your time on
    - automating process to make business better not building rag
    - chunking using ml models
    - mixture of retrivers 
- Reranker SOTA
    - it can follow instructions like whoes enotes are more important than the other
    - which publications information needs be high on rank than other
    - pritority based on source or format or type of document can also be takenc are of
    - conflicting information in the data
        - can be dealt with instruction based on recency or datasource
- Capability to say I dont know, and learn from that by taggin and post processing it in the bg for next time
- Agent : resoning capability after planning 
    - test time compute helps for this
- Not just retreiver
    - classifier to retreive or not
    - can add agentic layer to make it more dynamic
    - learnign from bad retreival
    - multi hop query like deducing
    - 
### Resource


### misc

---
## [Architecting Agent Memory: Principles, Patterns, and Best Practices â€” Richmond Alake, MongoDB](https://youtu.be/W2HVdB4Jbjs)
Release date : Jun 27, 2025 #memory #agent
### Idea
- Memory makes an agent better
- aim
    - stateless -> stateful
    - prompt -> persistence
    - response -> relationship

### Details
- agent is a spectrum : from prompt looping to fixed stesp to automate, workflow with decision making capability to autonomous
- Components : tools, planing, memory and perception
- memory types : 
    - short term
    - long term
    - working memory
    - cache
    - conversational
    - episodic
    - database
    - knowledge base
- copying human memory to make a proper agent
- to make them reliable, capabale, believable
- memory management
    - 
- perception types : image, txt, audio
- tools : function calling
- planning : react etc

### Resource
- https://github.com/RichmondAlake/memorizz

### misc

---


## [How Prompting is Evolving in the Next Age of AI](https://youtu.be/POLFZdG54Kw)
Release date : Jun 26, 2025 #prompt
### Idea
- 

### Details
1. use the big context window with a lot of context and history
2. extremely specificity, numebrs, xml tags
3. use the context window fully, documents, policies, emotions, codebase, mcp servers, thinking, situations een in prod as it can reason
4. let model work on multiple things (phases) or whole workflow with multiple steps in one go (not right now)
5. structred output is easier to get
6. prompts should encourage the model to ask questions, have the context setup that way, make it proactive
7. prompt should have self eval loop :check, evaluate, verify validate your work in the prompt
8. Dont give it options, it will bring best of both worlds, ask it to choose clearly
9. make the model think using prompt
10. the better or tight the prompt the better the output

### Resource


### misc

---

